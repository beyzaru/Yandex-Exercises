{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zbLLaSGH6Z"
      },
      "source": [
        "## Лабораторная работа \"Введение в ML\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3v975uGH6h"
      },
      "source": [
        "В этой лабораторной вы:\n",
        "\n",
        "- познакомитесь с базовыми библиотеками для работы с табличными данными — `numpy` и `pandas`\n",
        "- поближе посмотрите на простейшие задачи машинного обучения: классификацию и регрессию\n",
        "- попробуете несколько метрик и поймёте, почему выбор метрики это важно\n",
        "- обучите несколько простых моделей\n",
        "- увидите связь между сложностью модели и переобучением\n",
        "- убедитесь, что без данных всё тлен"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad3nBqBSGH6j"
      },
      "source": [
        "Загрузка самых базовых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Iht5qhGH6l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W8Eq0sTGH6n"
      },
      "source": [
        "### [NumPy](https://numpy.org/doc/stable/user/index.html)\n",
        "\n",
        "С 1995 numeric, с 2006 NumPy — «Numerical Python extensions» или просто «NumPy»\n",
        "\n",
        "Возможности библиотеки NumPy:\n",
        "* работать с многомерными массивами (таблицами)\n",
        "* быстро вычислять математические функций на многомерных массивах\n",
        "\n",
        "Ядро пакета NumPy — объект [ndarray](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)\n",
        "\n",
        "**Важные отличия** между NumPy arrays и Python sequences:\n",
        "* NumPy array имеет фиксированную длину, которая определяется в момент его создания (в отличие от Python lists, которые могут расти динамически)\n",
        "* Элементы в NumPy array должны быть одного типа\n",
        "* Можно выполнять операции непосредственно над NumPy arrays\n",
        "\n",
        "**Скорость** NumPy достигается с помощью:\n",
        "* реализации на C\n",
        "* векторизации и броадкастинга (broadcasting). Например, произведение массивов совместимых форм.\n",
        "\n",
        "Теперь давайте разберёмся подробнее и сделаем что-нибудь приятное и полезное в `numpy`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3UKcU6GH6o"
      },
      "source": [
        "### Индексация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqBzoEfvGH6p"
      },
      "source": [
        "В NumPy работает привычная индексация Python, ура! Включая использование отрицательных индексов и срезов (slices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anq_nSYTGH6q"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "<b>Замечание 1:</b> Индексы и срезы в многомерных массивах не нужно разделять квадратными скобками,\n",
        "т.е. вместо <b>matrix[i][j]</b> нужно использовать <b>matrix[i, j]</b>. Первое тоже работает, но сначала выдаёт строку i, потом элемент j в ней.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoHXSVIrGH6q"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "<b>Замечание 2:</b> Срезы в NumPy создают view, а не копии, как в случае срезов встроенных последовательностей Python (string, tuple and list).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJKxBB4dGH6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab2358f-1d5a-4138-9973-261501c6f30c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "ones_matrix = np.ones((5, 5))\n",
        "ones_submatrix_view = ones_matrix[::2,::2] # creates a view, not copy\n",
        "ones_matrix[::2,::2] = np.zeros((3, 3))\n",
        "ones_submatrix_view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpEF1rp2GH6v"
      },
      "source": [
        "### Ссылка на Яндекс.Контест\n",
        "\n",
        "Решения и ответы в задачах, расположенных ниже, загружайте в контест на автоматическую проверку:\n",
        "https://new.contest.yandex.ru/60376/start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZpuxPhJGH6v"
      },
      "source": [
        "**1.** Реализуйте функцию, принимающую на вход два одномерных массива `first_array` и `second_array` и возвращающую матрицу, в которой первый массив соответствует первому столбцу матрицы, второй — второму.\n",
        "\n",
        "Вероятно первое, что приходит вам на ум, это конкатенация и транспонирование:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmQk1N6rGH6w"
      },
      "outputs": [],
      "source": [
        "def construct_matrix(first_array, second_array):\n",
        "    \"\"\"\n",
        "    Construct matrix from pair of arrays\n",
        "    :param first_array: first array\n",
        "    :param second_array: second array\n",
        "    :return: constructed matrix\n",
        "    \"\"\"\n",
        "    return np.vstack([first_array, second_array]).T # <- your first right code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TeFqyCz4GH6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a298c1-a2c9-4c44-a572-8b921a3013dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 3],\n",
              "       [2, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "construct_matrix(np.array([1,2]),np.array([3,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP-lmcA2GH6y"
      },
      "source": [
        "(в скобках заметим, что конкатенировать можно vertically, horizontally, depth wise методами vstack, hstack, dstack по трём осям (0, 1 и 2, соотвественно), либо в общем случае `np.concatenate` — поиграйтесь ниже с прекрасным примером четырёхмерной точки, чтобы точно всё для себя понять)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xguxLJ0VGH6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20868b1c-e529-422a-8838-b26abf042fa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "p = np.arange(1).reshape([1, 1, 1, 1])\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1JFw75eGH6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba92ae60-b33d-4a98-b3b1-d471b6704ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vstack:  (2, 1, 1, 1)\n",
            "hstack:  (1, 2, 1, 1)\n",
            "dstack:  (1, 1, 2, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"vstack: \", np.vstack((p, p)).shape)\n",
        "print(\"hstack: \", np.hstack((p, p)).shape)\n",
        "print(\"dstack: \", np.dstack((p, p)).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvbthbDDGH6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be72e31-268d-4e2c-f896-64f47827d0de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "np.concatenate((p, p), axis=3).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5GkuWwaGH60"
      },
      "source": [
        "Но, поскольку операция транспонирования [делает массив non-contiguous](https://numpy.org/doc/stable/user/basics.copies.html#other-operations), мы в этой задаче **запретим** ей пользоваться и порекомедуем воспользоваться, например, методом [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ce_o75GH61"
      },
      "source": [
        "**2.** Реализуйте функцию, принимающую на вход массив целых неотрицательных чисел `nums` и возвращающую самый частый элемент массива."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZysMovaGH61"
      },
      "outputs": [],
      "source": [
        "def most_frequent(nums):\n",
        "    if len(nums) == 0:\n",
        "        return None\n",
        "    nums = np.asarray(nums)\n",
        "    counts = np.bincount(nums)\n",
        "    return np.argmax(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6kjITZMGH62"
      },
      "source": [
        "### Переходим к работе с данными\n",
        "\n",
        "Прежде всего, загрузим данные и сделаем из них красивые pandas-таблички. Они взяты из параллели RecSys соревнования https://yandex.ru/cup/ml/. Но мы будем иметь дело не со всеми данными, а только с их частью. Данные у нас будут про заведения общественного питания (больше бюрократический терминологии!)\n",
        "\n",
        "Файлы с данными можно найти [здесь](https://disk.yandex.ru/d/YWvCNRQMb7QSQA).\n",
        "\n",
        "Задачей будет **предсказание среднего чека** (average_bill) по некоторым другим свойствам заведения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJPF3OclGH62"
      },
      "outputs": [],
      "source": [
        "base = '/content/yndz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzDIu6uXGH62"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/sample_data/organisations.csv\")\n",
        "features = pd.read_csv(\"/content/sample_data/features.csv\")\n",
        "rubrics = pd.read_csv(\"/content/sample_data/rubrics.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4o5HprLwrWF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-AwDM7bGH63"
      },
      "source": [
        "В основном мы будем работать с табличкой `data`; остальное вам может пригодиться, если вы захотите знать, какое содержание стоит за кодами признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hrvEN_3GH63"
      },
      "source": [
        "## Изучение данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI9YQMuCGH63"
      },
      "source": [
        "Посмотрите на данные. В этом вам поможет метод ``head`` pandas-таблички."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA_0DG29GH64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "46ba5e25-5d68-4bf1-e82b-e15afe37dc13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 org_id city  average_bill    rating   rubrics_id  \\\n",
              "0  15903868628669802651  msk        1500.0  4.270968  30776 30774   \n",
              "1  16076540698036998306  msk         500.0  4.375000        30771   \n",
              "2   8129364761615040323  msk         500.0  4.000000        31495   \n",
              "3  15262729117594253452  msk         500.0  4.538813  30776 30770   \n",
              "4  13418544315327784420  msk         500.0  4.409091        31495   \n",
              "\n",
              "                                         features_id  \n",
              "0  3501685156 3501779478 20422 3502045016 3502045...  \n",
              "1  1509 1082283206 273469383 10462 11617 35017794...  \n",
              "2  10462 11177 11617 11629 1416 1018 11704 11867 ...  \n",
              "3  3501618484 2020795524 11629 11617 1018 11704 2...  \n",
              "4  11617 10462 11177 1416 11867 3501744275 20282 ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74440972-9930-4d7e-9569-6e766c5e60f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>org_id</th>\n",
              "      <th>city</th>\n",
              "      <th>average_bill</th>\n",
              "      <th>rating</th>\n",
              "      <th>rubrics_id</th>\n",
              "      <th>features_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15903868628669802651</td>\n",
              "      <td>msk</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>4.270968</td>\n",
              "      <td>30776 30774</td>\n",
              "      <td>3501685156 3501779478 20422 3502045016 3502045...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16076540698036998306</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>30771</td>\n",
              "      <td>1509 1082283206 273469383 10462 11617 35017794...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8129364761615040323</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>31495</td>\n",
              "      <td>10462 11177 11617 11629 1416 1018 11704 11867 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15262729117594253452</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.538813</td>\n",
              "      <td>30776 30770</td>\n",
              "      <td>3501618484 2020795524 11629 11617 1018 11704 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13418544315327784420</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.409091</td>\n",
              "      <td>31495</td>\n",
              "      <td>11617 10462 11177 1416 11867 3501744275 20282 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74440972-9930-4d7e-9569-6e766c5e60f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74440972-9930-4d7e-9569-6e766c5e60f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74440972-9930-4d7e-9569-6e766c5e60f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2d091045-d384-4d33-a3b9-334c918ab171\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d091045-d384-4d33-a3b9-334c918ab171')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2d091045-d384-4d33-a3b9-334c918ab171 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 68339,\n  \"fields\": [\n    {\n      \"column\": \"org_id\",\n      \"properties\": {\n        \"dtype\": \"uint64\",\n        \"num_unique_values\": 68339,\n        \"samples\": [\n          9456062215479570594,\n          13115319582926471866,\n          6942427175370541675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spb\",\n          \"msk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_bill\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41632.4963194898,\n        \"min\": 500.0,\n        \"max\": 7502000.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          250000.0,\n          50500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7081878962120907,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 13195,\n        \"samples\": [\n          4.294416243654823,\n          4.961538461538462\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rubrics_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 838,\n        \"samples\": [\n          \"30774 31286 31495\",\n          \"30771 30519 30774 31350 30776\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"features_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42521,\n        \"samples\": [\n          \"11177 1416 11704 11867 1018 273469383 10462 20422\",\n          \"20422 273469383 3501749289 3501745827 1524 20424 10462 11617 11177 11704 1415 11629 11867 20282 1082283206 1018 3501618484\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN9kZbURGH64"
      },
      "source": [
        "Полезно посмотреть внимательнее на то, с какими признаками нам предстоит работать.\n",
        "\n",
        "* **org_id** вам не понадобится;\n",
        "* **city** - город, в котором находится заведение (``msk`` или ``spb``);\n",
        "* **average_bill** - средний чек в заведении - он будет нашим таргетом;\n",
        "* **rating** - рейтинг заведения;\n",
        "* **rubrics_id** - тип заведения (или несколько типов). Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``rubrics``\n",
        "* **features_id** - набор неких фичей заведения. Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``features``\n",
        "\n",
        "Обратите внимание, что **rubrics_id** и **features_id** - это не списки, а разделённые пробелами строки. Когда вам захочется работать с отдельными фичами из мешка фичей для данного заведения, вам придётся всё-таки превратить их в списки (здесь поможет метод `split` для строк)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0IJIWz3GH64"
      },
      "source": [
        "Чтобы быстро восстанавливать по рубрикам и фичам их нормальные названия, сделайте словари вида ``код_фичи:название_фичи``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KwKEKr7GH65"
      },
      "outputs": [],
      "source": [
        "rubric_dict = rubrics.set_index('rubric_id')['rubric_name'].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dict = features.set_index('feature_id')['feature_name'].to_dict()"
      ],
      "metadata": {
        "id": "6lwhyUP1cvTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNd4PkyQGH65"
      },
      "source": [
        "Посмотрим, какими бывают типы заведений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "8WhaPPEeGH65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4e8d31-96f6-4265-bc5b-4edb4981ec02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{30519: 'Булочная, пекарня',\n",
              " 30770: 'Бар, паб',\n",
              " 30771: 'Быстрое питание',\n",
              " 30774: 'Кафе',\n",
              " 30775: 'Пиццерия',\n",
              " 30776: 'Ресторан',\n",
              " 30777: 'Столовая',\n",
              " 31286: 'Спортбар',\n",
              " 31350: 'Кондитерская',\n",
              " 31375: 'Суши-бар',\n",
              " 31401: 'Кальян-бар',\n",
              " 31495: 'Кофейня',\n",
              " 3108292683: 'Бар безалкогольных напитков',\n",
              " 3501514558: 'Фудкорт',\n",
              " 3501750896: 'Кофе с собой'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "rubric_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA6Bm_8EGH66"
      },
      "source": [
        "Мы что-то поняли про признаки, которыми нам предстоит пользоваться. Теперь время посмотреть на таргет. Вооружившись функциями ``hist`` и ``scatter`` из библиотеки ``matplotlib``, а также методом ``isna`` для pandas-таблиц разберитесь, какие значения принимают таргеты, есть ли там там выбросы, пропуски или ещё какие-то проблемы.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>Среди таргетов довольно много пропусков;</li>\n",
        "      <li>Все таргеты - это числа, кратные 500;</li>\n",
        "      <li>Есть какие-то адские значения, превышающие 100 000 (видимо, выбросы);</li>\n",
        "      <li>В целом, число ресторанов с данным средним чеком быстро падает с ростом среднего чека. Для средних чеков, больших 2500, заведений уже совсем мало. Примерно у 2/3 заведений средний чек 500.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "f6bg-kmIGH66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d5b9d5a2-4f95-4f07-f195-55369820587f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "org_id              0\n",
              "city                0\n",
              "average_bill    35561\n",
              "rating          13731\n",
              "rubrics_id          0\n",
              "features_id     11049\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>org_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_bill</th>\n",
              "      <td>35561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>13731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rubrics_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>features_id</th>\n",
              "      <td>11049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = data.dropna(subset=['average_bill']).copy()\n",
        "clean_data = clean_data[clean_data['average_bill'] <= 2500]\n",
        "print(f\"Rows: {len(clean_data)}\")"
      ],
      "metadata": {
        "id": "W893mA7PuIXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e7273a-2203-484a-d42e-4797fb969044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows after cleaning: 32136\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# @title average_bill\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "clean_data['average_bill'].plot(kind='hist', bins=20, title='average_bill')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "id": "uaHl7VPmJ5cq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "4f224e1a-e1f2-4264-8fd8-742cf9f26c58"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trfl5F_4GH66"
      },
      "source": [
        "**Базовая очистка данных**\n",
        "\n",
        "Раз есть треш, давайте чистить данные.\n",
        "\n",
        "С пропусками можно бороться по-разному (даже и с пропусками в таргете), но пока мы сделаем самую простую вещь: дропнем все заведения, для которых мы не знаем средний чек.\n",
        "\n",
        "Уберите из них все заведения, у которых средний чек неизвестен или превышает 2500. Пока есть опасение, что их слишком мало, чтобы мы смогли обучить на них что-нибудь.\n",
        "\n",
        "**3. Введите в Контест количество заведений, которое у вас получилось после очистки**.\n",
        "\n",
        "Дальше мы будем работать с очищенными данными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsNzGAp1GH67"
      },
      "source": [
        "**4. Посчитайте и введите в Контест разность между средними арифметическими average_bill в кафе Москвы и Санкт-Петербурга. Округлите ответ до целого.**\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Небольшая подсказка</summary>\n",
        "  Примените часто используемый метод groupby.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7b50a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47679bb-0a0d-4882-f8aa-e4bcc41a6334"
      },
      "source": [
        "cafe_rubric_id = next((str(rid) for rid, name in rubric_dict.items() if name == \"Кафе\"), None)\n",
        "\n",
        "if cafe_rubric_id:\n",
        "    cafe_data = clean_data[clean_data['rubrics_id'].str.contains(cafe_rubric_id, na=False)]\n",
        "    avg_bill_msk = cafe_data[cafe_data['city'] == 'msk']['average_bill'].mean()\n",
        "    avg_bill_spb = cafe_data[cafe_data['city'] == 'spb']['average_bill'].mean()\n",
        "    difference = round(avg_bill_msk - avg_bill_spb)\n",
        "    print(difference)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qncnmi8bGH7F"
      },
      "source": [
        "Давайте ещё немного поизучаем данные. Ответьте на вопросы:\n",
        "\n",
        "1. Есть ли разница между средними чеками в Москве и Санкт-Петербурге?\n",
        "2. Коррелирует ли средний чек с рейтингом?\n",
        "3. Есть ли разница в среднем чеке между ресторанами и пабами (см. соответствующие типы из ``rubrics``)?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>В целом, да. Вы могли бы сравнить средние (в Москве больше) или медианы (они равны, потому что уж больно много где средний чек 500). Этого, конечно, мало для того, чтобы сделать вывод. Нужно проверять какие-то статические критерии, которые изучаются в курсе по статистике. Не будем останавливаться на этом подробно. Поскольку данные совсем не нормальные, никакой t-тест не сработает; мы бы предложили использовать критерий Манна-Уитни (см. википедию и функцию mannwhitneyu из библиотеки scipy.stats).</li>\n",
        "      <li>Какая-то корреляция между ними есть но уж больно неубедительная (рекомендуем построим на одном графике boxplot рейтинга по каждому значению среднего чека для визуализации). Конечно, дна становится меньше с ростом среднего чека, но, видимо, в предсказании это особо не используешь;</li>\n",
        "      <li>Несомненно, в ресторанах средний чек выше. Это и невооружённым глазом видно, и с помощью критерия Манна-Уитни можно проверить.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATY5075lGH7F"
      },
      "source": [
        "## Формулируем задачу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znpEgJGIGH7F"
      },
      "source": [
        "Прежде, чем решать задачу, её надо сформулировать.\n",
        "\n",
        "**Вопрос первый**: это классификация или регрессия? Подумайте над этим.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    Ответ не столь однозначен, как хотелось бы. С одной стороны, таргет принимает всего четыре значения, и потому это может быть классификацией с 4 классами. С другой стороны, таргеты - это не абстрактные \"треугольник\", \"круг\", \"квадрат\", а вещественные числа, и когда мы вместо 500 предсказываем 2500, это явно хуже, чем вместо 1500 предсказать 2000. В целом, задачу можно решать и так, и так; мы будем смотреть на метрики обеих задач.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaVuazxsGH7G"
      },
      "source": [
        "**Вопрос второй**: какие метрики мы будем использовать для оценки качества решения? Какие метрики вы предложили бы для этой задачи как для задачи классификации? А для этой задачи, как для задачи регрессии?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Начнём с классификации. Метрика accuracy не очень хороша из-за несбалансированности классов. Действительно, классификатор, который всегда говорит 500, будет иметь accuracy примерно 0.66, хотя это никак не отражает практическую ценность модели. Как мы увидим, самая большая проблема будет заключаться в том, чтобы научиться выделять заведения с большими чеками, а их меньше всего и в accuracy они вносят самый маленький вклад. Есть разные способы с этим бороться, один -- использовать sklearn.metrics.balanced_accuracy_score. Его идея, грубо говоря, в том, чтобы по каждому классу найти, какая доля объектов этого класса правильно классифицирована, а потом эти доли усреднить. Тогда у бессмысленного классификатора, который всем ставит 500, будет скор 1/5 (ведь классов 5), а чтобы получить прежние 2/3, нужно будет научиться в каждом классе правильно ставить хотя бы 2/3 меток.    \n",
        "    \n",
        "    Теперь что касается регрессии. Основых метрики две - MSE и MAE. Из первой стоит извлекать корень, чтобы получать интерпретируемые человеком значения, а вторая менее агрессивна к выбросам (впрочем, выбросов тут уже нет, мы их все выкинули). Без дополнительной информации не очень понятно, какую выбирать, можно брать любую. А выбирать надо: ведь даже банальные модели \"предсказывай всегда среднее\" и \"предсказывай всегда медиану\" будут по-разному ранжироваться этими метриками.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs-jkCj-GH7G"
      },
      "source": [
        "**Вопрос третий**: а не взять ли нам какую-нибудь более экзотическую метрику? Например, MAPE (определение в учебнике в главе про оценку качества моделей). А как вам такое соображение: допустим, заказчик говорит, что пользователи будут расстраиваться, только если мы завысили средний чек - так давайте поправим MSE или MAE, обнуляя те слагаемые, для которых предсказанный таргет меньше истинного. Вот это хорошая метрика или нет?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Что касается MAPE, у нас нет тех проблем, с которой она борется. Вот если бы у нас были средние чеки от 500 до миллиона, мы бы столкнулись с ситуацией, что большие ошибки для больших чеков доминировали бы в сумме для MSE и MAE (500 вместо 1000 меркнет по сравнению с 500к вместо миллиона). Говоря поэтически, мы бы оптимизировали модель для миллионеров, забыв про простых трудяг. И было бы логично перейти от парадигмы \"ошибаемся на 500 рублей\" к парадигме \"ошибаемся на 50%\". Но у нас все таргеты примерно одного порядка, MAPE нам особо ни к чему.\n",
        "    \n",
        "    Вторая метрика коварна тем, что её можно \"накрутить\" безо всякой пользы для дела. А именно, модель, которая всегда предсказывает средний чек в миллион, была бы идеальна. Но все бы расстраивались и не ходили есть. Другое дело, что можно ввести разные веса для ошибок в большую и в меньшую сторону, но опять же - пока нет показаний к тому, что это нужно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCjV_SoAGH7G"
      },
      "source": [
        "## Применяем ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqkvcLSPGH7G"
      },
      "source": [
        "Теперь время разбить данные на обучающую и тестовую выборку. Делается это с помощью функции ``train_test_split`` из пакета ``sklearn``. При этом очень важно сделать две вещи:\n",
        "\n",
        "* Зафиксировать ``random_state=42`` (да, именно этот, а то ваши модели могут не зайти в Контест), чтобы всё, что мы делаем, было воспроизводимо (иначе от перезапуска к перезапуску числа могут меняться, и мы не будем понимать, из-за чего это происходит).\n",
        "* Сделать стратификацию по таргету. В противном случае у нас в трейне и тесте могут оказаться разные пропорции классов (обычно особенно страдают мало представленные классы), что неутешительно скажется на результате.\n",
        "\n",
        "**Обратите внимание**, что если вы побьёте выборку на train и test по-другому, ваши результаты могут не зайти в контест."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF2IVpOjGH7H"
      },
      "outputs": [],
      "source": [
        "clean_data_train, clean_data_test = train_test_split(\n",
        "    clean_data, stratify=clean_data['average_bill'], test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S161veFJGH7H"
      },
      "source": [
        "Теперь нам нужен **бейзлайн** - очень простая модель, с которой мы в дальнейшем будем сравниваться.\n",
        "\n",
        "Поскольку мы ещё не знаем никаких умных классов моделей, все модели мы будем писать руками. А именно, мы напишем две простых модели на основе ``sklearn.baseRegressorMixin`` и ``sklearn.base.ClassifierMixin`` (посмотрите примеры в документации sklearn и сделайте так же):\n",
        "\n",
        "* Модель для задачи регрессии, которая для всех заведений предсказывает одно число — среднее значение среднего чека;\n",
        "* Модель для задачи классификации, которая для всех заведений предсказывает один класс — самый частый класс (ироничным образом он в данном случае совпадает с медианой).\n",
        "\n",
        "**Важно!** Мы будем много раз повторять вам мантру о том, что **информация из тестовой выборки не должна протекать в процесс обучения**. Так вот, и среднее, и самый частый класс вы должны считать именно на обучающей выборке!\n",
        "\n",
        "**5 и 6. Напишите эти две модели и сдайте в Контест**. В процессе проверки модели будут и обучаться, и предсказывать.\n",
        "\n",
        "Заметим, что для этих моделей нам вообще не нужны какие-то \"фичи\"; мы работаем только с таргетом.\n",
        "\n",
        "У каждой модели есть (как минимум) два метода: `fit` (обучает модель по фичам `X` и таргету `y`) `predict` (предсказывает по фичам `X`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLz_sxtUGH7H"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import RegressorMixin, ClassifierMixin\n",
        "\n",
        "class MeanRegressor(RegressorMixin):\n",
        "    def fit(self, X=None, y=None):\n",
        "        self.mean_ = np.mean(y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        return np.full(shape=(X.shape[0],), fill_value=self.mean_)\n",
        "\n",
        "\n",
        "class MostFrequentClassifier(ClassifierMixin):\n",
        "    def fit(self, X=None, y=None):\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        self.most_frequent_class_ = values[np.argmax(counts)]\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        return np.full(shape=(X.shape[0],), fill_value=self.most_frequent_class_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo2pNhVoGH7I"
      },
      "source": [
        "Обучим наши модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arXlaGnTGH7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3586ab0f-abf3-47de-c21a-0d496940e4c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.MostFrequentClassifier at 0x796a7577e360>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "reg = MeanRegressor()\n",
        "reg.fit(y=clean_data_train['average_bill'])\n",
        "\n",
        "clf = MostFrequentClassifier()\n",
        "clf.fit(y=clean_data_train['average_bill'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_reg = reg.predict(X=np.zeros((len(clean_data_test), 1)))\n",
        "\n",
        "y_pred_clf = clf.predict(X=np.zeros((len(clean_data_test), 1)))\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, balanced_accuracy_score\n",
        "\n",
        "y_test = clean_data_test['average_bill']\n",
        "\n",
        "rmse_reg = np.sqrt(mean_squared_error(y_test, y_pred_reg))\n",
        "rmse_clf = np.sqrt(mean_squared_error(y_test, y_pred_clf))\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred_clf)\n",
        "\n",
        "print(\"RMSE (Regression):\", rmse_reg)\n",
        "print(\"RMSE (Classification):\", rmse_clf)\n",
        "print(\"Balanced Accuracy (Classification):\", balanced_acc)\n"
      ],
      "metadata": {
        "id": "Kr9WCysVatvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29f5e1e-43d3-4d90-a96a-86c57ee4635a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE (Regression): 448.7143889551622\n",
            "RMSE (Classification): 514.7517402382093\n",
            "Balanced Accuracy (Classification): 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJG8x0tmGH7I"
      },
      "source": [
        "Обучите модели и оцените их качество на тестовой выборке. В качестве метрик возьмём RMSE (``np.sqrt`` от ``sklearn.metrics.mean_squared_error``) и ``sklearn.metrics.balanced_accuracy_score``.\n",
        "\n",
        "Для регрессионной модели имеет смысл считать только RMSE (значения будут не кратны 500, точно мы угадывать не будем никогда), а вот для классификационной можно найти обе метрики. Сделайте это. Какая модель оказалась лучше по RMSE?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvZwp54sGH7J"
      },
      "source": [
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда</summary>\n",
        "    \n",
        "  Казалось бы, регрессор никогда не угадывает, но он в каком-то смысле лучше классификатора - справедливо ли это? Возможно. Несуществующий пользователь модели вряд ли будет задавать вопросы \"почему средний чек не кратен 500?\" Ну, выдали около 800 - ок, понятно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-1-O9GyGH7J"
      },
      "source": [
        "## Усложнение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGWgxl0VGH7J"
      },
      "source": [
        "Бейзлайны будут нашей отправной точкой. Строя дальнейшие модели, мы будем спрашивать себя: получилось ли лучше бейзлайна? Если нет или если не особо, то в чём смысл усложнения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3DkuuFGH7K"
      },
      "source": [
        "Начнём с использования фичи ``city``. Мы уже видели, что в разных городах и средние чеки разные. Легко проверить, что *медиана* средних чеков всё же одна и та же и в Москве, и в Санкт-Петербурге (ох уж этот вездесущий средний чек 500!), поэтому с классификатором мы ничего не сделаем. Но вот регрессор можно попробовать починить.\n",
        "\n",
        "**7. Напишите регрессор, для каждого заведения предсказывающий среднее значение в том же городе (на обучающей выборке, конечно) и сдайте его в Контест**. Вам может помочь то, что булевы `pandas` и `numpy` столбцы можно умножать на численные — в такой ситуации False работает, как ноль, а True как единица."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZULQVPe2GH7K"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CityMeanRegressor(RegressorMixin):\n",
        "    def fit(self, X=None, y=None):\n",
        "        self.city_means_ = {city: y[X['city']==city].mean() for city in X['city'].unique()}\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        return np.array([self.city_means_[city] for city in X['city']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = clean_data_train['average_bill']\n",
        "y_test  = clean_data_test['average_bill']\n",
        "\n",
        "X_train = clean_data_train[['city']]\n",
        "X_test  = clean_data_test[['city']]\n"
      ],
      "metadata": {
        "id": "0KbrWnq6jt4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_city = CityMeanRegressor().fit(X_train, y_train)\n",
        "y_pred_city = reg_city.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Edq6eXyjkCa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "rmse_city = np.sqrt(mean_squared_error(y_test, y_pred_city))\n",
        "print(\"RMSE (CityMeanRegressor):\", rmse_city)\n"
      ],
      "metadata": {
        "id": "K1t0g-2nkFSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22813231-e928-4eac-a72b-b19cd1e41049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE (CityMeanRegressor): 445.1063281403263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EeFGk24GH7K"
      },
      "source": [
        "Обучите регрессор и сравните его по метрике RMSE с бейзлайнами. Получилось ли улучшить метрику?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jROycei1GH7L"
      },
      "source": [
        "Лучше стало, но, правда, не очень сильно. В этот момент очень важно не просто радовать руководителя приростом в третьем знаке, но и думать о том, что происходит.\n",
        "\n",
        "Средний средний чек по Москве равен 793, в Санкт-Петербурге - 676, а в целом - 752 рубля. MSE, увы, не поможет вам ответить на вопрос, стало ли лучше пользователю, если вы ему вместо 752 рублей назвали 793. Здесь вскрывается весьма существенный порок MSE в этой задаче. Дело в том, что наш изначальный таргет делит заведения на некоторые \"ценовые категории\", и различие в средних чеках 500 и 1000 в самом деле существенно. Наверное, мы хотели бы как раз правильно предсказывать ценовые категории. Но MSE не очень помогает нам об этом судить. Дальше мы ещё подумаем, как это исправить.\n",
        "\n",
        "В любом случае, несмотря на улучшение метрики, мы пока не можем судить, стало ли по жизни лучше от усложнения модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEQ9eOoWGH7L"
      },
      "source": [
        "Поручинившись немного, возьмём на вооружение другую идею. Давайте использовать типы заведений!\n",
        "\n",
        "Но с типами есть некоторая проблема: в столбце ``rubrics_id`` не всегда один идентификатор, часто их несколько, и всего комбинаций довольно много. Чтобы не возиться с малочисленными типами, давайте сольём их в один безликий ``other``.\n",
        "\n",
        "Итак, добавьте в обучающие и тестовые данные столбец ``modified_rubrics``, в котором будет то же, что и в ``rubrics_id``, если соответствующая комбинация рубрик содержит хотя бы 100 заведений из обучающей (!) выборки, и строка ``other`` в противном случае.\n",
        "\n",
        "Здесь вам поможет контейнер ``Counter`` из библиотеки ``collections``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTVW5KkwGH7L"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "rubric_counts = Counter(clean_data_train['rubrics_id'])\n",
        "\n",
        "def modify_rubric(r):\n",
        "    return r if rubric_counts.get(r, 0) >= 100 else 'other'\n",
        "\n",
        "clean_data_train['modified_rubrics'] = clean_data_train['rubrics_id'].apply(modify_rubric)\n",
        "clean_data_test['modified_rubrics']  = clean_data_test['rubrics_id'].apply(modify_rubric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZXhpBjnGH7L"
      },
      "source": [
        "Теперь настало время написать могучий классификатор, который по заведению предсказывает медиану средних чеков среди тех в обучающей выборке, у которых с ним одинаковые `modified_rubrics` и город (вы спросите, почему медиану, а не самый частый -- спишем это на вдохновение; самый частый тоже можно брать - но медиана работает лучше).\n",
        "\n",
        "**8. Напишите классификатор и сдайте в Контест**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTfcwh5dGH7M"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RubricCityMedianClassifier(ClassifierMixin):\n",
        "    def fit(self, X, y):\n",
        "        self.medians_ = X.copy()\n",
        "        self.medians_['target'] = y\n",
        "        self.group_medians_ = self.medians_.groupby(['city', 'modified_rubrics'])['target'].median().to_dict()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = [self.group_medians_[(row['city'], row['modified_rubrics'])] for _, row in X.iterrows()]\n",
        "        return np.array(preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = clean_data_test[['city','modified_rubrics']]\n",
        "y_test = clean_data_test['average_bill']\n",
        "\n",
        "clf_rubric = RubricCityMedianClassifier().fit(\n",
        "    clean_data_train[['city','modified_rubrics']],\n",
        "    clean_data_train['average_bill']\n",
        ")\n",
        "\n",
        "y_pred_rubric = clf_rubric.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmse_rubric = np.sqrt(mean_squared_error(y_test, y_pred_rubric))\n",
        "print(\"RMSE\", rmse_rubric)\n"
      ],
      "metadata": {
        "id": "PsmLFxp0lzyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a79070b-0062-4008-bdf0-18d51684f0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE (RubricCityMedianClassifier): 393.96675836287915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgjbwgkGH7M"
      },
      "source": [
        "Сравните обученный классификатор по метрикам RMSE и balanced_accuracy_score с нашими бейзлайнами. Получилось ли улучшить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMjsnCnQGH7M"
      },
      "source": [
        "Обратите внимание что рост accuracy по сравнению с бейзлайном при этом на порядок меньше:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2cF0I-CGH7M"
      },
      "source": [
        "accuracy_score\n",
        "\n",
        "Predict most frequent:  0.6947666195190948\n",
        "\n",
        "Predict by rubric and city:  0.7095709570957096"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylrAIjCcGH7N"
      },
      "source": [
        "Для диагностики напечатайте для каждого класса тестовой выборки, сколько в нём объектов и скольким из них наш классификатор приписал правильный класс. Что вы видите?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "  Вы, вероятно, видите то, что мы стали однозначно лучше по сравнению с бейзлайном детектировать средний чек 1000 и 1500 (хотя всё равно не очень хорошо + ценой ухудшения качества на среднем чеке 500), а вот чеки 2000 и 2500 нам ну никак не даются.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ScOy7ZvGH7N"
      },
      "source": [
        "**Кстати**. А вы понимаете, почему приведённый выше пайплайн классификации был не очень удачным с точки зрения архитектуры? Почему его было бы правильнее воплотить по-другому?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "Собственно говоря, и не было никакого пайплайна. К счастью, у нас была одна обучающая выборка, мы на ней посчитали список рубрик для modified_rubrics и радовались жизни. Но если бы нам надо было переобучать всё на новых данных, пришлось бы помнить, что их надо везде пересчитать (ведь у нас могли появиться новые рубрики с хотя бы 100 представителями). А уж никакую кросс-валидацию (кто знает - тот поймёт) с нашим подходом к делу и вовсе бы не получилось сделать без боли.\n",
        "    \n",
        "Поэтому в следующей лабораторной вы научитесь делать честные пайплайны, в которых преобразование данных, генерация фичей и обучение классификатора будут объединены в один понятный процесс, происходящий на этапе fit.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ujl3tbbGH7N"
      },
      "source": [
        "## Слишком простые и слишком сложные модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF7McCHsGH7N"
      },
      "source": [
        "Бейзлайны у нас слишком просты и потому не очень полезны в жизни. Но если сложность модели растёт бесконтрольно, то тоже получается плохо.\n",
        "\n",
        "Давайте рассмотрим конкретный пример. Создадим классификатор, использующий одновременно `rubrics_id` и `features_id`.\n",
        "\n",
        "Сделайте следующее:\n",
        "\n",
        "- для каждого объекта обучающей выборки сконкатенируйте строку `rubrics_id` с разделителем (например, буквой 'q') и содержимым `features_id`. Полученный столбец озаглавьте `modified_features`. Это не самый клёвый способ заиспользовать все фичи, но сейчас пока сойдёт. Причём на сей раз не будем выкидывать мало представленные значения (вся информация важна, не так ли?).\n",
        "- при этом для тестовой выборке заменяйте на строку `other` все конкатенации, которые не встретились в обучающей выборке.\n",
        "\n",
        "То есть элементы в этом столбце будут иметь вид `other` или `30776 30774 q 3502045032 11741 3502045016 1046...`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = clean_data_train.copy()\n",
        "\n",
        "train[\"modified_features\"] = train[\"rubrics_id\"].astype(str).str.strip() + \" q \" + train[\"features_id\"].astype(str).str.strip()\n",
        "\n",
        "train = train.drop(columns=[\"rubrics_id\", \"features_id\"])\n",
        "train.head()\n"
      ],
      "metadata": {
        "id": "RqVtwmRb3pFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "3ede03f2-450f-4e4f-bb44-447f6484b447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     org_id city  average_bill    rating modified_rubrics  \\\n",
              "45769   3276960721840719260  msk         500.0  4.500000            30770   \n",
              "39061   8452997364765928283  msk        1500.0  4.442623      30774 30776   \n",
              "59281  14240408259222214074  spb        1000.0  4.018868      30776 30774   \n",
              "51225  15114069072602161053  msk        1500.0  4.364742            other   \n",
              "29587   2730337118800634815  msk        1000.0  4.698718            30770   \n",
              "\n",
              "                                       modified_features  \n",
              "45769    30770 q 11704 20422 1018 11177 1416 11867 10462  \n",
              "39061  30774 30776 q 1415 3501481355 1416 11629 10462...  \n",
              "59281  30776 30774 q 3502045032 11741 3502045016 1046...  \n",
              "51225  31401 30776 q 3501513153 3501779478 3491142672...  \n",
              "29587  30770 q 21247 10896 3491142672 11629 350148135...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08b00e2e-902f-4aba-a075-597cb537cbb8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>org_id</th>\n",
              "      <th>city</th>\n",
              "      <th>average_bill</th>\n",
              "      <th>rating</th>\n",
              "      <th>modified_rubrics</th>\n",
              "      <th>modified_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45769</th>\n",
              "      <td>3276960721840719260</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>30770</td>\n",
              "      <td>30770 q 11704 20422 1018 11177 1416 11867 10462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39061</th>\n",
              "      <td>8452997364765928283</td>\n",
              "      <td>msk</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>4.442623</td>\n",
              "      <td>30774 30776</td>\n",
              "      <td>30774 30776 q 1415 3501481355 1416 11629 10462...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59281</th>\n",
              "      <td>14240408259222214074</td>\n",
              "      <td>spb</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>4.018868</td>\n",
              "      <td>30776 30774</td>\n",
              "      <td>30776 30774 q 3502045032 11741 3502045016 1046...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51225</th>\n",
              "      <td>15114069072602161053</td>\n",
              "      <td>msk</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>4.364742</td>\n",
              "      <td>other</td>\n",
              "      <td>31401 30776 q 3501513153 3501779478 3491142672...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29587</th>\n",
              "      <td>2730337118800634815</td>\n",
              "      <td>msk</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>4.698718</td>\n",
              "      <td>30770</td>\n",
              "      <td>30770 q 21247 10896 3491142672 11629 350148135...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08b00e2e-902f-4aba-a075-597cb537cbb8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08b00e2e-902f-4aba-a075-597cb537cbb8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08b00e2e-902f-4aba-a075-597cb537cbb8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86c7439f-f29a-41a5-a6c3-f7d18a521bf7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86c7439f-f29a-41a5-a6c3-f7d18a521bf7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86c7439f-f29a-41a5-a6c3-f7d18a521bf7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 21531,\n  \"fields\": [\n    {\n      \"column\": \"org_id\",\n      \"properties\": {\n        \"dtype\": \"uint64\",\n        \"num_unique_values\": 21531,\n        \"samples\": [\n          15375887114102838250,\n          18157368579727951306,\n          13756871786476710783\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spb\",\n          \"msk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_bill\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 448.56650459102184,\n        \"min\": 500.0,\n        \"max\": 2500.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1500.0,\n          2000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5851355238816538,\n        \"min\": 0.6666666666666666,\n        \"max\": 5.0,\n        \"num_unique_values\": 7490,\n        \"samples\": [\n          4.432312252964427,\n          4.34435261707989\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified_rubrics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"30775\",\n          \"30770 30774\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified_features\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20915,\n        \"samples\": [\n          \"30774 q 11177 10462 11704 273469383 1416 20424 1018 20422 11867 601\",\n          \"30775 q 1018 20422 11704 273469383 1416 20424 1415 3501744275 11617 10462\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = clean_data_train.copy()\n",
        "test = clean_data_test.copy()\n",
        "\n",
        "# Training set için birleştir ve eski sütunları kaldır\n",
        "train[\"modified_features\"] = train[\"rubrics_id\"].astype(str).str.strip() + \" q \" + train[\"features_id\"].astype(str).str.strip()\n",
        "train = train.drop(columns=[\"rubrics_id\", \"features_id\"])\n",
        "\n",
        "# Test set için birleştir\n",
        "test[\"modified_features\"] = test[\"rubrics_id\"].astype(str).str.strip() + \" q \" + test[\"features_id\"].astype(str).str.strip()\n",
        "\n",
        "# Testte train’de olmayanları 'other' yap\n",
        "seen = set(train[\"modified_features\"])\n",
        "test[\"modified_features\"] = test[\"modified_features\"].apply(lambda x: x if x in seen else \"other\")\n",
        "test.head()"
      ],
      "metadata": {
        "id": "At1rHIsP34hO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "492e04df-75fb-45b8-95c3-292a273221c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     org_id city  average_bill    rating         rubrics_id  \\\n",
              "65841  14385912302763770021  spb        1000.0  4.748444  30776 30770 31401   \n",
              "48882  16695436192794975203  msk         500.0  3.793758              30771   \n",
              "33711  11841431940065207518  msk         500.0  3.606557        30771 30777   \n",
              "33544  16028521499441205186  msk        2000.0  4.683841              30776   \n",
              "35293  12477116204055673498  spb         500.0  4.165394  30776 31401 30770   \n",
              "\n",
              "                                             features_id modified_rubrics  \\\n",
              "65841  11177 3501618484 10462 3501481355 1509 1416 20...            other   \n",
              "48882  3501744275 273469383 3501513153 11617 10462 11...            30771   \n",
              "33711  3501773763 3501744275 3501773764 3501618484 15...            other   \n",
              "33544  3501618484 20422 1082283206 11704 11629 21247 ...            30776   \n",
              "35293  1524 246 11704 1018 3501618484 2020795524 2124...            other   \n",
              "\n",
              "      modified_features  \n",
              "65841             other  \n",
              "48882             other  \n",
              "33711             other  \n",
              "33544             other  \n",
              "35293             other  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31af805c-ca56-486a-b307-38e30a9badbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>org_id</th>\n",
              "      <th>city</th>\n",
              "      <th>average_bill</th>\n",
              "      <th>rating</th>\n",
              "      <th>rubrics_id</th>\n",
              "      <th>features_id</th>\n",
              "      <th>modified_rubrics</th>\n",
              "      <th>modified_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65841</th>\n",
              "      <td>14385912302763770021</td>\n",
              "      <td>spb</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>4.748444</td>\n",
              "      <td>30776 30770 31401</td>\n",
              "      <td>11177 3501618484 10462 3501481355 1509 1416 20...</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48882</th>\n",
              "      <td>16695436192794975203</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>3.793758</td>\n",
              "      <td>30771</td>\n",
              "      <td>3501744275 273469383 3501513153 11617 10462 11...</td>\n",
              "      <td>30771</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33711</th>\n",
              "      <td>11841431940065207518</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>3.606557</td>\n",
              "      <td>30771 30777</td>\n",
              "      <td>3501773763 3501744275 3501773764 3501618484 15...</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33544</th>\n",
              "      <td>16028521499441205186</td>\n",
              "      <td>msk</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>4.683841</td>\n",
              "      <td>30776</td>\n",
              "      <td>3501618484 20422 1082283206 11704 11629 21247 ...</td>\n",
              "      <td>30776</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35293</th>\n",
              "      <td>12477116204055673498</td>\n",
              "      <td>spb</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.165394</td>\n",
              "      <td>30776 31401 30770</td>\n",
              "      <td>1524 246 11704 1018 3501618484 2020795524 2124...</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31af805c-ca56-486a-b307-38e30a9badbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31af805c-ca56-486a-b307-38e30a9badbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31af805c-ca56-486a-b307-38e30a9badbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e8e18ef1-13b0-4e8f-ac0c-1f58ba35f05b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8e18ef1-13b0-4e8f-ac0c-1f58ba35f05b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e8e18ef1-13b0-4e8f-ac0c-1f58ba35f05b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 10605,\n  \"fields\": [\n    {\n      \"column\": \"org_id\",\n      \"properties\": {\n        \"dtype\": \"uint64\",\n        \"num_unique_values\": 10605,\n        \"samples\": [\n          15625077510401014174,\n          4366489577485934079,\n          6173940981519752498\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"msk\",\n          \"spb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_bill\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 448.7355250579826,\n        \"min\": 500.0,\n        \"max\": 2500.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          500.0,\n          2500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5897605572325794,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 4200,\n        \"samples\": [\n          3.48,\n          4.2264808362369335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rubrics_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 432,\n        \"samples\": [\n          \"30771 30519 30774 31350 30776\",\n          \"30776 30777\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"features_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10121,\n        \"samples\": [\n          \"10462 11629 3501773764 1415 11839 11177 3501773763 11617 11704 3501744275 11741 3501513153 3501765089 3501481353 3491142672 1189498238 273469383 21247 3501745827 1018 20422 11867 3501779478 3501754799 3501749289 246\",\n          \"1082283206 20305 11704 21247 11629 20422 1018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified_rubrics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"30771 30774\",\n          \"30776 31375\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified_features\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 307,\n        \"samples\": [\n          \"31495 q 11704 11629 11867 20282 20422 11177 273469383\",\n          \"30771 q 10462 11704 1018 20422 20424 273469383\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train, test = clean_data_train.copy(), clean_data_test.copy()\n",
        "\n",
        "train[\"modified_features\"] = train[\"rubrics_id\"].astype(str).str.strip() + \" q \" + train[\"features_id\"].astype(str).str.strip()\n",
        "train = train.drop(columns=[\"rubrics_id\", \"features_id\"])\n",
        "\n",
        "test[\"modified_features\"] = test[\"rubrics_id\"].astype(str).str.strip() + \" q \" + test[\"features_id\"].astype(str).str.strip()\n",
        "seen = set(train[\"modified_features\"])\n",
        "test[\"modified_features\"] = test[\"modified_features\"].apply(lambda x: x if x in seen else \"other\")\n",
        "\n",
        "medians = train.groupby(\"modified_features\")[\"average_bill\"].median()\n",
        "global_median = train[\"average_bill\"].median()\n",
        "\n",
        "y_pred = []\n",
        "for mf in tqdm(test[\"modified_features\"]):\n",
        "    y_pred.append(medians.get(mf, global_median))\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"index\": test.index,\n",
        "    \"prediction\": y_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False, header=False, float_format=\"%.2f\")\n",
        "print(submission)"
      ],
      "metadata": {
        "id": "L0IHjJ7I4w_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f102b751-b74d-4ccb-d57f-1fb389520565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10605/10605 [00:00<00:00, 168991.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       index  prediction\n",
            "0      65841       500.0\n",
            "1      48882       500.0\n",
            "2      33711       500.0\n",
            "3      33544       500.0\n",
            "4      35293       500.0\n",
            "...      ...         ...\n",
            "10600  55337       500.0\n",
            "10601  64048       500.0\n",
            "10602  22010       500.0\n",
            "10603  40089       500.0\n",
            "10604  32180       500.0\n",
            "\n",
            "[10605 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AllFeaturesMedianClassifier(ClassifierMixin):\n",
        "    def __init__(self):\n",
        "      self.allFeatures_median_dict = None\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "      data = pd.DataFrame({'city' : X['city'], 'rating' : X['rating'], 'rubrics_id' : X['rubrics_id'], 'features_id' : X['features_id'], 'modified_features' : X['modified_features'], 'average_bill': y})\n",
        "      self.allFeatures_median_dict = data.groupby(['modified_features'])['average_bill'].median().to_dict()\n",
        "      return self\n",
        "\n",
        "    def predict(self, X):\n",
        "      predictions = []\n",
        "      for idx, row in X.iterrows():\n",
        "            key = row['modified_features']\n",
        "            if key in self.allFeatures_median_dict:\n",
        "                predictions.append(self.allFeatures_median_dict[key])\n",
        "            else:\n",
        "                predictions.append(np.median(list(self.allFeatures_median_dict.values())))\n",
        "      return np.array(predictions)"
      ],
      "metadata": {
        "id": "Rqwm_5D-v7DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8tNBPzVGH7O"
      },
      "source": [
        "Теперь обучите классификатор, который для заведения предсказывает медиану среднего чека по всем объектам тестовой выборки с таким же, как у него, значением `modified_features`, а если такого в обучающей выборке нет, то глобальную медиану среднего чека по всей обучающей выборке.\n",
        "\n",
        "**9. Загрузите в Контест предсказания этого классификатора на тестовой выборке**\n",
        "\n",
        "Мы ждём файла **.csv**, у которого в каждой строке будет только одно число - предсказание классификатора.\n",
        "\n",
        "Возможно, вам будет полезна библиотека ``tqdm``, позволяющая отслеживать в реальном времени, сколько времени уже крутится цикл и сколько итераций ещё осталось. Впрочем, если вы всё написали нормально, то должно работать не очень долго."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XrswPW4GH7O"
      },
      "source": [
        "Модель, очевидно, очень сложная. Число параметров (различных категорий) в ней сопоставимо с числом объектов в обучающей выборке. А получилось ли хорошо?\n",
        "\n",
        "Давайте посчитаем RMSE и balanced_accuracy_score на обучающей и на тестовой выборках.\n",
        "\n",
        "**10. Введите их в Контест**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_medianClassifier = AllFeaturesMedianClassifier().fit(train, train['average_bill']).predict(test)\n",
        "predictions_medianClassifier_forTrain = AllFeaturesMedianClassifier().fit(train, train['average_bill']).predict(train)\n",
        "rmse_forTrain = np.sqrt(mean_squared_error(clean_data_train['average_bill'], predictions_medianClassifier_forTrain))\n",
        "bas_forTrain = balanced_accuracy_score(clean_data_train['average_bill'], predictions_medianClassifier_forTrain)\n",
        "\n",
        "rmse_forTest = np.sqrt(mean_squared_error(clean_data_test['average_bill'], predictions_medianClassifier))\n",
        "bas_forTest = balanced_accuracy_score(clean_data_test['average_bill'], predictions_medianClassifier)\n",
        "\n",
        "print('RMSE for train: ', rmse_forTrain)\n",
        "print('Balanced accuracy score for train: ', bas_forTrain)\n",
        "print('RMSE for test: ', rmse_forTest)\n",
        "print('Balanced accuracy score for test: ', bas_forTest)"
      ],
      "metadata": {
        "id": "tRGK_wIukDbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f474b1-a06c-45aa-aab1-10a2bcf6692b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE for train:  32.4162067388783\n",
            "Balanced accuracy score for train:  0.9931928777769354\n",
            "RMSE for test:  513.9898108867789\n",
            "Balanced accuracy score for test:  0.2010249213051401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TeINeOmd2-1Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGDTpxFgGH7O"
      },
      "source": [
        "Налицо переобучение: на трейне метрики отличные, на тесте - вообще никакие\n",
        "\n",
        "В общем, не гонитесь за чрезмерной сложностью модели.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTU2yubYGH7O"
      },
      "source": [
        "## ML без данных что компутер без электричества"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVOCVf2GH7P"
      },
      "source": [
        "Возможно, вы смотрите на полученные выше результаты и думаете: вот если бы мы не какие-то убогие медианы предсказывали, а гоняли бы нейросети, то тут-то бы всё и получилось!\n",
        "\n",
        "Но, увы, совсем даже не всегда от счастья нас отделяет выбор хорошей модели (и стратегии обучения). Если данные не очень, то даже самая крутая модель не сработает. В этой ситуации нужно либо добывать новые фичи каким-то образом, либо собирать новые данные (увеличивать датасет), либо просто бросать задачу.\n",
        "\n",
        "Давайте посмотрим, что выжмет из наших данных одна из самых мощных моделей для табличных данных - градиентный бустинг на решающих деревьях в исполнении [CatBoost](https://catboost.ai/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0L4UmzSGH7P"
      },
      "source": [
        "Но прежде, чем сделать fit, нам надо облагородить данные. Несмотря на то, что CatBoost отлично работает с категориальными фичами, мешок признаков из `rubrics_id` или `features_id` может ему оказаться не по зубам. Поэтому мы соберём датасет в пристойную матрицу, создав для каждого типа рубрик и фичей отдельный столбец и записав там единицы для тех объектов, у которых эта рубрика или фича имеет место.\n",
        "\n",
        "В матрице почти все элементы будут нулями. Такие матрицы считаются **разреженными** и их можно хранить гораздо эффективней, чем просто таблицей. Этим и займёмся)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJKuMtNbGH7P"
      },
      "source": [
        "Есть несколько форматов хранения разреженных матриц (многие из них реализованы в [пакете sparse библиотеки scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)), и каждый пригоден для чего-то своего.\n",
        "\n",
        "Создавать разреженную матрицу лучше в [формате COO](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_array.html#scipy.sparse.coo_array). Он предполагает, что разреженная матрица задаётся в виде трёх списков: `row`, `col`, `data`, причём каждая тройка `(row[i], col[i], data[i])` кодирует элемент со значением `data[i]`, стоящий на позиции `(row[i], col[i])`. Считается, что на позициях `(row, col)`, которые ни разу не встретились, стоят нули.\n",
        "\n",
        "Нетрудно видеть, что заполнять такую матрицу - одно удовольствие, и особенно этому помогает тот факт, что **пара `(row, col)` может встретиться несколько раз** (тогда в итоговой матрице на соответствующей позиции стоит сумма соответствующих `data[i]`). Но, с другой стороны, почти ничего другого с такой матрицей не сделаешь: произвольного доступа к элементам она не предоставляет, умножить её тоже особо ничего не умножишь. Поэтому для дальнейшего использования созданную таким образом матрицу преобразуют в один из более удобных форматов, например, [CSR (compressed sparse row)](https://scipy-lectures.org/advanced/scipy_sparse/csr_matrix.html). Он, к примеру, хорошо подходит для умножения на вектор (потому что матрица хранится по строкам). Не будем разбирать его подробно, но можете почитать по ссылке, если интересно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hd_Sob3GH7P"
      },
      "source": [
        "Вам нужно будет превратить обучающие и тестовые данные в разреженные матрицы `sparse_data_train` и `sparse_data_test` соответственно, таким образом, что:\n",
        "\n",
        "- столбец `city` превратится в столбец из единиц и нулей (например, 1 - Москва, 0 - Питер);\n",
        "- столбец `rating` перекочует в разреженные матрицы без изменений;\n",
        "- каждый типы рубрик и каждая фича превратятся в отдельный 0-1-принак;\n",
        "\n",
        "В тестовой выборке будут фичи, которых в обучающей выборке не было. С ними можно по-разному работать, но давайте создадим дополнительную фантомную фичу `feature_other`, в которой будет то, сколько неизвестных по обучающей выборке фичей есть у данного объекта."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-UAatGJGH7P"
      },
      "outputs": [],
      "source": [
        "def dummiesRubricsAndFeatures(data, unique_rubrics=None, unique_features=None):\n",
        "\n",
        "    temp = pd.DataFrame()\n",
        "    temp['rubric_id'] = data['rubrics_id'].str.split(' ')\n",
        "    temp['feature_id'] = data['features_id'].str.split(' ')\n",
        "\n",
        "\n",
        "    if unique_rubrics is None:\n",
        "        unique_rubrics = set()\n",
        "        for ids in temp['rubric_id']:\n",
        "            unique_rubrics.update(ids)\n",
        "    if unique_features is None:\n",
        "        unique_features = set()\n",
        "        for ids in temp['feature_id']:\n",
        "            unique_features.update(ids)\n",
        "\n",
        "\n",
        "    for rubric in unique_rubrics:\n",
        "        temp['rubric' + rubric] = temp['rubric_id'].apply(lambda x: 1 if rubric in x else 0)\n",
        "\n",
        "    for feature in unique_features:\n",
        "        temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
        "\n",
        "    if unique_features is not None: # this one only for the test\n",
        "        def count_other_features(feature_list):\n",
        "            if isinstance(feature_list, list):\n",
        "                return sum(1 for f in feature_list if f not in unique_features)\n",
        "            return 0 # in case of nan and non-type lists\n",
        "\n",
        "        temp['feature_other'] = temp['feature_id'].apply(count_other_features)\n",
        "\n",
        "\n",
        "    # removing original columns\n",
        "    temp = temp.drop(['rubric_id', 'feature_id'], axis=1)\n",
        "    result = pd.concat([pd.get_dummies(data['city']).astype(int), data['rating'], temp], axis=1)\n",
        "\n",
        "    return result, unique_rubrics, unique_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_data_train = dummiesRubricsAndFeatures(clean_data_train)\n",
        "sparse_data_test = pd.concat([pd.get_dummies(clean_data_test['city']).astype(int), clean_data_test['rating']], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JHJ5XOomwVq-",
        "outputId": "dc3704f0-3803-47f2-e6f7-b4052ae7bb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature' + feature] = temp['feature_id'].apply(lambda x: 1 if feature in x else 0)\n",
            "/tmp/ipython-input-3961738736.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp['feature_other'] = temp['feature_id'].apply(count_other_features)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_data_train[0].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "collapsed": true,
        "id": "QxyzwqZvwZPm",
        "outputId": "ba828fd8-dfc6-4ce9-a028-a374eaad6d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       msk  spb    rating  rubric30774  rubric31375  rubric30519  rubric30777  \\\n",
              "45769    1    0  4.500000            0            0            0            0   \n",
              "39061    1    0  4.442623            1            0            0            0   \n",
              "59281    0    1  4.018868            1            0            0            0   \n",
              "51225    1    0  4.364742            0            0            0            0   \n",
              "29587    1    0  4.698718            0            0            0            0   \n",
              "\n",
              "       rubric30776  rubric30771  rubric31350  ...  feature1524  \\\n",
              "45769            0            0            0  ...            0   \n",
              "39061            1            0            0  ...            1   \n",
              "59281            1            0            0  ...            0   \n",
              "51225            1            0            0  ...            0   \n",
              "29587            0            0            0  ...            1   \n",
              "\n",
              "       feature3501599538  feature803  feature3501509029  feature20819  \\\n",
              "45769                  0           0                  0             0   \n",
              "39061                  0           0                  0             0   \n",
              "59281                  0           0                  0             0   \n",
              "51225                  0           0                  0             0   \n",
              "29587                  0           0                  0             0   \n",
              "\n",
              "       feature10722  feature21001  feature11977  feature11982  feature_other  \n",
              "45769             0             0             0             0              0  \n",
              "39061             0             0             0             0              0  \n",
              "59281             0             0             0             0              0  \n",
              "51225             0             0             0             0              0  \n",
              "29587             0             0             0             0              0  \n",
              "\n",
              "[5 rows x 606 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0268f896-e13d-4963-a1c8-d4f2889ca811\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>msk</th>\n",
              "      <th>spb</th>\n",
              "      <th>rating</th>\n",
              "      <th>rubric30774</th>\n",
              "      <th>rubric31375</th>\n",
              "      <th>rubric30519</th>\n",
              "      <th>rubric30777</th>\n",
              "      <th>rubric30776</th>\n",
              "      <th>rubric30771</th>\n",
              "      <th>rubric31350</th>\n",
              "      <th>...</th>\n",
              "      <th>feature1524</th>\n",
              "      <th>feature3501599538</th>\n",
              "      <th>feature803</th>\n",
              "      <th>feature3501509029</th>\n",
              "      <th>feature20819</th>\n",
              "      <th>feature10722</th>\n",
              "      <th>feature21001</th>\n",
              "      <th>feature11977</th>\n",
              "      <th>feature11982</th>\n",
              "      <th>feature_other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45769</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39061</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.442623</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59281</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.018868</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51225</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.364742</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29587</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.698718</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 606 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0268f896-e13d-4963-a1c8-d4f2889ca811')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0268f896-e13d-4963-a1c8-d4f2889ca811 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0268f896-e13d-4963-a1c8-d4f2889ca811');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5e757646-e466-44a1-a744-82fbb20ea27c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e757646-e466-44a1-a744-82fbb20ea27c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5e757646-e466-44a1-a744-82fbb20ea27c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eDEWq5IjwimY",
        "outputId": "f1bce5aa-c8c7-4048-9622-578c813e127f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFfj-1E4GH7Q"
      },
      "source": [
        "Данные готовы, и теперь можно запустить катбуст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2lP5NouGH7Q"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpW6uR0oGH7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ed102e12-f359-4e27-e233-c8854498faec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.092536\n",
            "0:\tlearn: 1.4339518\ttotal: 252ms\tremaining: 4m 11s\n",
            "1:\tlearn: 1.3104246\ttotal: 438ms\tremaining: 3m 38s\n",
            "2:\tlearn: 1.2214524\ttotal: 638ms\tremaining: 3m 31s\n",
            "3:\tlearn: 1.1512131\ttotal: 826ms\tremaining: 3m 25s\n",
            "4:\tlearn: 1.0961756\ttotal: 1.03s\tremaining: 3m 24s\n",
            "5:\tlearn: 1.0464715\ttotal: 1.2s\tremaining: 3m 19s\n",
            "6:\tlearn: 1.0033534\ttotal: 1.39s\tremaining: 3m 17s\n",
            "7:\tlearn: 0.9687791\ttotal: 1.57s\tremaining: 3m 14s\n",
            "8:\tlearn: 0.9370911\ttotal: 1.73s\tremaining: 3m 10s\n",
            "9:\tlearn: 0.9119297\ttotal: 1.9s\tremaining: 3m 8s\n",
            "10:\tlearn: 0.8871469\ttotal: 2.06s\tremaining: 3m 5s\n",
            "11:\tlearn: 0.8669697\ttotal: 2.15s\tremaining: 2m 57s\n",
            "12:\tlearn: 0.8499156\ttotal: 2.25s\tremaining: 2m 50s\n",
            "13:\tlearn: 0.8351714\ttotal: 2.35s\tremaining: 2m 45s\n",
            "14:\tlearn: 0.8198310\ttotal: 2.44s\tremaining: 2m 40s\n",
            "15:\tlearn: 0.8045810\ttotal: 2.54s\tremaining: 2m 36s\n",
            "16:\tlearn: 0.7947472\ttotal: 2.63s\tremaining: 2m 31s\n",
            "17:\tlearn: 0.7833267\ttotal: 2.73s\tremaining: 2m 28s\n",
            "18:\tlearn: 0.7738633\ttotal: 2.81s\tremaining: 2m 24s\n",
            "19:\tlearn: 0.7651956\ttotal: 2.92s\tremaining: 2m 22s\n",
            "20:\tlearn: 0.7562836\ttotal: 3s\tremaining: 2m 20s\n",
            "21:\tlearn: 0.7500306\ttotal: 3.12s\tremaining: 2m 18s\n",
            "22:\tlearn: 0.7435031\ttotal: 3.21s\tremaining: 2m 16s\n",
            "23:\tlearn: 0.7383219\ttotal: 3.3s\tremaining: 2m 14s\n",
            "24:\tlearn: 0.7331305\ttotal: 3.4s\tremaining: 2m 12s\n",
            "25:\tlearn: 0.7271477\ttotal: 3.49s\tremaining: 2m 10s\n",
            "26:\tlearn: 0.7242043\ttotal: 3.56s\tremaining: 2m 8s\n",
            "27:\tlearn: 0.7207533\ttotal: 3.65s\tremaining: 2m 6s\n",
            "28:\tlearn: 0.7164637\ttotal: 3.74s\tremaining: 2m 5s\n",
            "29:\tlearn: 0.7127064\ttotal: 3.83s\tremaining: 2m 3s\n",
            "30:\tlearn: 0.7089936\ttotal: 3.92s\tremaining: 2m 2s\n",
            "31:\tlearn: 0.7066393\ttotal: 4s\tremaining: 2m 1s\n",
            "32:\tlearn: 0.7027752\ttotal: 4.11s\tremaining: 2m\n",
            "33:\tlearn: 0.6993229\ttotal: 4.19s\tremaining: 1m 59s\n",
            "34:\tlearn: 0.6967066\ttotal: 4.3s\tremaining: 1m 58s\n",
            "35:\tlearn: 0.6942556\ttotal: 4.41s\tremaining: 1m 58s\n",
            "36:\tlearn: 0.6917464\ttotal: 4.5s\tremaining: 1m 57s\n",
            "37:\tlearn: 0.6900590\ttotal: 4.6s\tremaining: 1m 56s\n",
            "38:\tlearn: 0.6872709\ttotal: 4.69s\tremaining: 1m 55s\n",
            "39:\tlearn: 0.6860184\ttotal: 4.77s\tremaining: 1m 54s\n",
            "40:\tlearn: 0.6850578\ttotal: 4.84s\tremaining: 1m 53s\n",
            "41:\tlearn: 0.6832262\ttotal: 4.94s\tremaining: 1m 52s\n",
            "42:\tlearn: 0.6811958\ttotal: 5.03s\tremaining: 1m 51s\n",
            "43:\tlearn: 0.6793573\ttotal: 5.12s\tremaining: 1m 51s\n",
            "44:\tlearn: 0.6784927\ttotal: 5.21s\tremaining: 1m 50s\n",
            "45:\tlearn: 0.6750705\ttotal: 5.31s\tremaining: 1m 50s\n",
            "46:\tlearn: 0.6737155\ttotal: 5.4s\tremaining: 1m 49s\n",
            "47:\tlearn: 0.6733665\ttotal: 5.48s\tremaining: 1m 48s\n",
            "48:\tlearn: 0.6720223\ttotal: 5.57s\tremaining: 1m 48s\n",
            "49:\tlearn: 0.6710021\ttotal: 5.64s\tremaining: 1m 47s\n",
            "50:\tlearn: 0.6705119\ttotal: 5.72s\tremaining: 1m 46s\n",
            "51:\tlearn: 0.6689102\ttotal: 5.8s\tremaining: 1m 45s\n",
            "52:\tlearn: 0.6682766\ttotal: 5.89s\tremaining: 1m 45s\n",
            "53:\tlearn: 0.6669563\ttotal: 5.99s\tremaining: 1m 44s\n",
            "54:\tlearn: 0.6662255\ttotal: 6.08s\tremaining: 1m 44s\n",
            "55:\tlearn: 0.6647412\ttotal: 6.19s\tremaining: 1m 44s\n",
            "56:\tlearn: 0.6642168\ttotal: 6.27s\tremaining: 1m 43s\n",
            "57:\tlearn: 0.6623050\ttotal: 6.39s\tremaining: 1m 43s\n",
            "58:\tlearn: 0.6606383\ttotal: 6.5s\tremaining: 1m 43s\n",
            "59:\tlearn: 0.6598524\ttotal: 6.59s\tremaining: 1m 43s\n",
            "60:\tlearn: 0.6592437\ttotal: 6.67s\tremaining: 1m 42s\n",
            "61:\tlearn: 0.6588961\ttotal: 6.76s\tremaining: 1m 42s\n",
            "62:\tlearn: 0.6585285\ttotal: 6.84s\tremaining: 1m 41s\n",
            "63:\tlearn: 0.6571332\ttotal: 6.93s\tremaining: 1m 41s\n",
            "64:\tlearn: 0.6568651\ttotal: 7.01s\tremaining: 1m 40s\n",
            "65:\tlearn: 0.6562896\ttotal: 7.09s\tremaining: 1m 40s\n",
            "66:\tlearn: 0.6556349\ttotal: 7.18s\tremaining: 1m 40s\n",
            "67:\tlearn: 0.6546012\ttotal: 7.3s\tremaining: 1m 40s\n",
            "68:\tlearn: 0.6534473\ttotal: 7.38s\tremaining: 1m 39s\n",
            "69:\tlearn: 0.6533719\ttotal: 7.47s\tremaining: 1m 39s\n",
            "70:\tlearn: 0.6523818\ttotal: 7.63s\tremaining: 1m 39s\n",
            "71:\tlearn: 0.6521792\ttotal: 7.79s\tremaining: 1m 40s\n",
            "72:\tlearn: 0.6520347\ttotal: 7.91s\tremaining: 1m 40s\n",
            "73:\tlearn: 0.6509779\ttotal: 8.08s\tremaining: 1m 41s\n",
            "74:\tlearn: 0.6507604\ttotal: 8.25s\tremaining: 1m 41s\n",
            "75:\tlearn: 0.6505017\ttotal: 8.45s\tremaining: 1m 42s\n",
            "76:\tlearn: 0.6502470\ttotal: 8.68s\tremaining: 1m 44s\n",
            "77:\tlearn: 0.6499992\ttotal: 8.86s\tremaining: 1m 44s\n",
            "78:\tlearn: 0.6488055\ttotal: 9.05s\tremaining: 1m 45s\n",
            "79:\tlearn: 0.6484955\ttotal: 9.26s\tremaining: 1m 46s\n",
            "80:\tlearn: 0.6482091\ttotal: 9.49s\tremaining: 1m 47s\n",
            "81:\tlearn: 0.6481468\ttotal: 9.7s\tremaining: 1m 48s\n",
            "82:\tlearn: 0.6477752\ttotal: 9.92s\tremaining: 1m 49s\n",
            "83:\tlearn: 0.6473156\ttotal: 10.2s\tremaining: 1m 51s\n",
            "84:\tlearn: 0.6463899\ttotal: 10.3s\tremaining: 1m 51s\n",
            "85:\tlearn: 0.6460722\ttotal: 10.5s\tremaining: 1m 51s\n",
            "86:\tlearn: 0.6451275\ttotal: 10.8s\tremaining: 1m 53s\n",
            "87:\tlearn: 0.6444503\ttotal: 10.9s\tremaining: 1m 53s\n",
            "88:\tlearn: 0.6433520\ttotal: 11.1s\tremaining: 1m 53s\n",
            "89:\tlearn: 0.6430466\ttotal: 11.3s\tremaining: 1m 54s\n",
            "90:\tlearn: 0.6426881\ttotal: 11.4s\tremaining: 1m 54s\n",
            "91:\tlearn: 0.6424785\ttotal: 11.6s\tremaining: 1m 54s\n",
            "92:\tlearn: 0.6421515\ttotal: 11.8s\tremaining: 1m 54s\n",
            "93:\tlearn: 0.6410621\ttotal: 11.9s\tremaining: 1m 54s\n",
            "94:\tlearn: 0.6409949\ttotal: 12.1s\tremaining: 1m 55s\n",
            "95:\tlearn: 0.6406874\ttotal: 12.3s\tremaining: 1m 55s\n",
            "96:\tlearn: 0.6400481\ttotal: 12.5s\tremaining: 1m 55s\n",
            "97:\tlearn: 0.6393308\ttotal: 12.8s\tremaining: 1m 58s\n",
            "98:\tlearn: 0.6386045\ttotal: 13.1s\tremaining: 1m 59s\n",
            "99:\tlearn: 0.6384721\ttotal: 13.4s\tremaining: 2m\n",
            "100:\tlearn: 0.6376119\ttotal: 13.7s\tremaining: 2m 1s\n",
            "101:\tlearn: 0.6372463\ttotal: 14s\tremaining: 2m 3s\n",
            "102:\tlearn: 0.6368177\ttotal: 14.3s\tremaining: 2m 4s\n",
            "103:\tlearn: 0.6365444\ttotal: 14.5s\tremaining: 2m 5s\n",
            "104:\tlearn: 0.6362213\ttotal: 14.8s\tremaining: 2m 5s\n",
            "105:\tlearn: 0.6360200\ttotal: 14.9s\tremaining: 2m 5s\n",
            "106:\tlearn: 0.6358244\ttotal: 15.1s\tremaining: 2m 5s\n",
            "107:\tlearn: 0.6349131\ttotal: 15.4s\tremaining: 2m 7s\n",
            "108:\tlearn: 0.6348250\ttotal: 15.6s\tremaining: 2m 7s\n",
            "109:\tlearn: 0.6340395\ttotal: 15.9s\tremaining: 2m 8s\n",
            "110:\tlearn: 0.6339788\ttotal: 16s\tremaining: 2m 8s\n",
            "111:\tlearn: 0.6338004\ttotal: 16.2s\tremaining: 2m 8s\n",
            "112:\tlearn: 0.6332219\ttotal: 16.4s\tremaining: 2m 8s\n",
            "113:\tlearn: 0.6325594\ttotal: 16.5s\tremaining: 2m 8s\n",
            "114:\tlearn: 0.6322794\ttotal: 16.7s\tremaining: 2m 8s\n",
            "115:\tlearn: 0.6314446\ttotal: 16.9s\tremaining: 2m 8s\n",
            "116:\tlearn: 0.6309769\ttotal: 17.1s\tremaining: 2m 9s\n",
            "117:\tlearn: 0.6306569\ttotal: 17.3s\tremaining: 2m 9s\n",
            "118:\tlearn: 0.6302815\ttotal: 17.6s\tremaining: 2m 10s\n",
            "119:\tlearn: 0.6297733\ttotal: 17.8s\tremaining: 2m 10s\n",
            "120:\tlearn: 0.6291952\ttotal: 18s\tremaining: 2m 11s\n",
            "121:\tlearn: 0.6290824\ttotal: 18.3s\tremaining: 2m 11s\n",
            "122:\tlearn: 0.6287928\ttotal: 18.4s\tremaining: 2m 11s\n",
            "123:\tlearn: 0.6276116\ttotal: 18.6s\tremaining: 2m 11s\n",
            "124:\tlearn: 0.6268358\ttotal: 18.9s\tremaining: 2m 11s\n",
            "125:\tlearn: 0.6267468\ttotal: 19.1s\tremaining: 2m 12s\n",
            "126:\tlearn: 0.6261415\ttotal: 19.3s\tremaining: 2m 12s\n",
            "127:\tlearn: 0.6257325\ttotal: 19.4s\tremaining: 2m 12s\n",
            "128:\tlearn: 0.6249974\ttotal: 19.6s\tremaining: 2m 12s\n",
            "129:\tlearn: 0.6248122\ttotal: 19.8s\tremaining: 2m 12s\n",
            "130:\tlearn: 0.6245528\ttotal: 20s\tremaining: 2m 12s\n",
            "131:\tlearn: 0.6243337\ttotal: 20.2s\tremaining: 2m 12s\n",
            "132:\tlearn: 0.6238125\ttotal: 20.4s\tremaining: 2m 13s\n",
            "133:\tlearn: 0.6233762\ttotal: 20.6s\tremaining: 2m 13s\n",
            "134:\tlearn: 0.6228685\ttotal: 20.8s\tremaining: 2m 13s\n",
            "135:\tlearn: 0.6225796\ttotal: 21s\tremaining: 2m 13s\n",
            "136:\tlearn: 0.6221228\ttotal: 21.3s\tremaining: 2m 13s\n",
            "137:\tlearn: 0.6220350\ttotal: 21.4s\tremaining: 2m 13s\n",
            "138:\tlearn: 0.6218015\ttotal: 21.6s\tremaining: 2m 13s\n",
            "139:\tlearn: 0.6215404\ttotal: 21.8s\tremaining: 2m 13s\n",
            "140:\tlearn: 0.6210785\ttotal: 22s\tremaining: 2m 14s\n",
            "141:\tlearn: 0.6197249\ttotal: 22.2s\tremaining: 2m 14s\n",
            "142:\tlearn: 0.6194390\ttotal: 22.4s\tremaining: 2m 14s\n",
            "143:\tlearn: 0.6191833\ttotal: 22.6s\tremaining: 2m 14s\n",
            "144:\tlearn: 0.6190751\ttotal: 22.8s\tremaining: 2m 14s\n",
            "145:\tlearn: 0.6189487\ttotal: 22.9s\tremaining: 2m 14s\n",
            "146:\tlearn: 0.6182495\ttotal: 23.1s\tremaining: 2m 14s\n",
            "147:\tlearn: 0.6176986\ttotal: 23.2s\tremaining: 2m 13s\n",
            "148:\tlearn: 0.6175907\ttotal: 23.3s\tremaining: 2m 13s\n",
            "149:\tlearn: 0.6173689\ttotal: 23.4s\tremaining: 2m 12s\n",
            "150:\tlearn: 0.6169885\ttotal: 23.5s\tremaining: 2m 12s\n",
            "151:\tlearn: 0.6162451\ttotal: 23.6s\tremaining: 2m 11s\n",
            "152:\tlearn: 0.6155622\ttotal: 23.7s\tremaining: 2m 11s\n",
            "153:\tlearn: 0.6153812\ttotal: 23.8s\tremaining: 2m 10s\n",
            "154:\tlearn: 0.6150712\ttotal: 23.9s\tremaining: 2m 10s\n",
            "155:\tlearn: 0.6148049\ttotal: 24s\tremaining: 2m 9s\n",
            "156:\tlearn: 0.6140671\ttotal: 24.1s\tremaining: 2m 9s\n",
            "157:\tlearn: 0.6136152\ttotal: 24.1s\tremaining: 2m 8s\n",
            "158:\tlearn: 0.6132195\ttotal: 24.3s\tremaining: 2m 8s\n",
            "159:\tlearn: 0.6128393\ttotal: 24.4s\tremaining: 2m 7s\n",
            "160:\tlearn: 0.6128181\ttotal: 24.4s\tremaining: 2m 7s\n",
            "161:\tlearn: 0.6126227\ttotal: 24.5s\tremaining: 2m 6s\n",
            "162:\tlearn: 0.6123142\ttotal: 24.6s\tremaining: 2m 6s\n",
            "163:\tlearn: 0.6120692\ttotal: 24.7s\tremaining: 2m 5s\n",
            "164:\tlearn: 0.6117306\ttotal: 24.8s\tremaining: 2m 5s\n",
            "165:\tlearn: 0.6116271\ttotal: 24.8s\tremaining: 2m 4s\n",
            "166:\tlearn: 0.6114185\ttotal: 24.9s\tremaining: 2m 4s\n",
            "167:\tlearn: 0.6112538\ttotal: 25s\tremaining: 2m 3s\n",
            "168:\tlearn: 0.6111971\ttotal: 25.1s\tremaining: 2m 3s\n",
            "169:\tlearn: 0.6109212\ttotal: 25.2s\tremaining: 2m 2s\n",
            "170:\tlearn: 0.6106753\ttotal: 25.3s\tremaining: 2m 2s\n",
            "171:\tlearn: 0.6104264\ttotal: 25.4s\tremaining: 2m 2s\n",
            "172:\tlearn: 0.6101902\ttotal: 25.5s\tremaining: 2m 1s\n",
            "173:\tlearn: 0.6099666\ttotal: 25.6s\tremaining: 2m 1s\n",
            "174:\tlearn: 0.6098070\ttotal: 25.8s\tremaining: 2m 1s\n",
            "175:\tlearn: 0.6096923\ttotal: 25.9s\tremaining: 2m 1s\n",
            "176:\tlearn: 0.6093507\ttotal: 26.1s\tremaining: 2m 1s\n",
            "177:\tlearn: 0.6092463\ttotal: 26.2s\tremaining: 2m 1s\n",
            "178:\tlearn: 0.6090822\ttotal: 26.4s\tremaining: 2m 1s\n",
            "179:\tlearn: 0.6089257\ttotal: 26.5s\tremaining: 2m\n",
            "180:\tlearn: 0.6087096\ttotal: 26.7s\tremaining: 2m\n",
            "181:\tlearn: 0.6085323\ttotal: 26.8s\tremaining: 2m\n",
            "182:\tlearn: 0.6080216\ttotal: 27s\tremaining: 2m\n",
            "183:\tlearn: 0.6079853\ttotal: 27.1s\tremaining: 2m\n",
            "184:\tlearn: 0.6077427\ttotal: 27.3s\tremaining: 2m\n",
            "185:\tlearn: 0.6076732\ttotal: 27.5s\tremaining: 2m\n",
            "186:\tlearn: 0.6072749\ttotal: 27.6s\tremaining: 2m\n",
            "187:\tlearn: 0.6069957\ttotal: 27.8s\tremaining: 1m 59s\n",
            "188:\tlearn: 0.6068812\ttotal: 27.9s\tremaining: 1m 59s\n",
            "189:\tlearn: 0.6066036\ttotal: 28.1s\tremaining: 1m 59s\n",
            "190:\tlearn: 0.6064877\ttotal: 28.2s\tremaining: 1m 59s\n",
            "191:\tlearn: 0.6061503\ttotal: 28.3s\tremaining: 1m 59s\n",
            "192:\tlearn: 0.6057305\ttotal: 28.4s\tremaining: 1m 58s\n",
            "193:\tlearn: 0.6056042\ttotal: 28.5s\tremaining: 1m 58s\n",
            "194:\tlearn: 0.6054929\ttotal: 28.6s\tremaining: 1m 58s\n",
            "195:\tlearn: 0.6049432\ttotal: 28.7s\tremaining: 1m 57s\n",
            "196:\tlearn: 0.6047724\ttotal: 28.8s\tremaining: 1m 57s\n",
            "197:\tlearn: 0.6045839\ttotal: 28.9s\tremaining: 1m 56s\n",
            "198:\tlearn: 0.6042253\ttotal: 29s\tremaining: 1m 56s\n",
            "199:\tlearn: 0.6040205\ttotal: 29.1s\tremaining: 1m 56s\n",
            "200:\tlearn: 0.6037598\ttotal: 29.1s\tremaining: 1m 55s\n",
            "201:\tlearn: 0.6036711\ttotal: 29.2s\tremaining: 1m 55s\n",
            "202:\tlearn: 0.6035215\ttotal: 29.3s\tremaining: 1m 55s\n",
            "203:\tlearn: 0.6032733\ttotal: 29.4s\tremaining: 1m 54s\n",
            "204:\tlearn: 0.6031888\ttotal: 29.5s\tremaining: 1m 54s\n",
            "205:\tlearn: 0.6031180\ttotal: 29.6s\tremaining: 1m 53s\n",
            "206:\tlearn: 0.6025339\ttotal: 29.7s\tremaining: 1m 53s\n",
            "207:\tlearn: 0.6024357\ttotal: 29.7s\tremaining: 1m 53s\n",
            "208:\tlearn: 0.6024002\ttotal: 29.8s\tremaining: 1m 52s\n",
            "209:\tlearn: 0.6022527\ttotal: 29.9s\tremaining: 1m 52s\n",
            "210:\tlearn: 0.6021900\ttotal: 30s\tremaining: 1m 52s\n",
            "211:\tlearn: 0.6019541\ttotal: 30.1s\tremaining: 1m 51s\n",
            "212:\tlearn: 0.6016809\ttotal: 30.1s\tremaining: 1m 51s\n",
            "213:\tlearn: 0.6015641\ttotal: 30.2s\tremaining: 1m 50s\n",
            "214:\tlearn: 0.6015472\ttotal: 30.3s\tremaining: 1m 50s\n",
            "215:\tlearn: 0.6013756\ttotal: 30.4s\tremaining: 1m 50s\n",
            "216:\tlearn: 0.6013056\ttotal: 30.4s\tremaining: 1m 49s\n",
            "217:\tlearn: 0.6011525\ttotal: 30.5s\tremaining: 1m 49s\n",
            "218:\tlearn: 0.6008783\ttotal: 30.6s\tremaining: 1m 49s\n",
            "219:\tlearn: 0.6008641\ttotal: 30.7s\tremaining: 1m 48s\n",
            "220:\tlearn: 0.6006072\ttotal: 30.8s\tremaining: 1m 48s\n",
            "221:\tlearn: 0.6005200\ttotal: 30.9s\tremaining: 1m 48s\n",
            "222:\tlearn: 0.6001232\ttotal: 31s\tremaining: 1m 47s\n",
            "223:\tlearn: 0.5996712\ttotal: 31s\tremaining: 1m 47s\n",
            "224:\tlearn: 0.5995243\ttotal: 31.1s\tremaining: 1m 47s\n",
            "225:\tlearn: 0.5992254\ttotal: 31.2s\tremaining: 1m 46s\n",
            "226:\tlearn: 0.5990583\ttotal: 31.3s\tremaining: 1m 46s\n",
            "227:\tlearn: 0.5988789\ttotal: 31.4s\tremaining: 1m 46s\n",
            "228:\tlearn: 0.5988029\ttotal: 31.4s\tremaining: 1m 45s\n",
            "229:\tlearn: 0.5984254\ttotal: 31.6s\tremaining: 1m 45s\n",
            "230:\tlearn: 0.5983865\ttotal: 31.6s\tremaining: 1m 45s\n",
            "231:\tlearn: 0.5983449\ttotal: 31.7s\tremaining: 1m 45s\n",
            "232:\tlearn: 0.5980437\ttotal: 31.8s\tremaining: 1m 44s\n",
            "233:\tlearn: 0.5978576\ttotal: 31.9s\tremaining: 1m 44s\n",
            "234:\tlearn: 0.5977932\ttotal: 32s\tremaining: 1m 44s\n",
            "235:\tlearn: 0.5976197\ttotal: 32.1s\tremaining: 1m 43s\n",
            "236:\tlearn: 0.5973262\ttotal: 32.2s\tremaining: 1m 43s\n",
            "237:\tlearn: 0.5972941\ttotal: 32.2s\tremaining: 1m 43s\n",
            "238:\tlearn: 0.5970662\ttotal: 32.3s\tremaining: 1m 42s\n",
            "239:\tlearn: 0.5968016\ttotal: 32.4s\tremaining: 1m 42s\n",
            "240:\tlearn: 0.5966611\ttotal: 32.5s\tremaining: 1m 42s\n",
            "241:\tlearn: 0.5964389\ttotal: 32.6s\tremaining: 1m 42s\n",
            "242:\tlearn: 0.5963252\ttotal: 32.7s\tremaining: 1m 41s\n",
            "243:\tlearn: 0.5961276\ttotal: 32.8s\tremaining: 1m 41s\n",
            "244:\tlearn: 0.5958290\ttotal: 32.9s\tremaining: 1m 41s\n",
            "245:\tlearn: 0.5957821\ttotal: 32.9s\tremaining: 1m 40s\n",
            "246:\tlearn: 0.5952238\ttotal: 33s\tremaining: 1m 40s\n",
            "247:\tlearn: 0.5946858\ttotal: 33.1s\tremaining: 1m 40s\n",
            "248:\tlearn: 0.5944405\ttotal: 33.2s\tremaining: 1m 40s\n",
            "249:\tlearn: 0.5940996\ttotal: 33.3s\tremaining: 1m 39s\n",
            "250:\tlearn: 0.5940360\ttotal: 33.4s\tremaining: 1m 39s\n",
            "251:\tlearn: 0.5939019\ttotal: 33.5s\tremaining: 1m 39s\n",
            "252:\tlearn: 0.5937918\ttotal: 33.5s\tremaining: 1m 39s\n",
            "253:\tlearn: 0.5937781\ttotal: 33.6s\tremaining: 1m 38s\n",
            "254:\tlearn: 0.5937086\ttotal: 33.7s\tremaining: 1m 38s\n",
            "255:\tlearn: 0.5932430\ttotal: 33.8s\tremaining: 1m 38s\n",
            "256:\tlearn: 0.5931949\ttotal: 33.9s\tremaining: 1m 37s\n",
            "257:\tlearn: 0.5931254\ttotal: 34s\tremaining: 1m 37s\n",
            "258:\tlearn: 0.5929274\ttotal: 34s\tremaining: 1m 37s\n",
            "259:\tlearn: 0.5927301\ttotal: 34.1s\tremaining: 1m 37s\n",
            "260:\tlearn: 0.5926197\ttotal: 34.2s\tremaining: 1m 36s\n",
            "261:\tlearn: 0.5924873\ttotal: 34.3s\tremaining: 1m 36s\n",
            "262:\tlearn: 0.5924399\ttotal: 34.4s\tremaining: 1m 36s\n",
            "263:\tlearn: 0.5921077\ttotal: 34.5s\tremaining: 1m 36s\n",
            "264:\tlearn: 0.5917397\ttotal: 34.6s\tremaining: 1m 35s\n",
            "265:\tlearn: 0.5913276\ttotal: 34.7s\tremaining: 1m 35s\n",
            "266:\tlearn: 0.5913145\ttotal: 34.8s\tremaining: 1m 35s\n",
            "267:\tlearn: 0.5912618\ttotal: 34.8s\tremaining: 1m 35s\n",
            "268:\tlearn: 0.5912461\ttotal: 34.9s\tremaining: 1m 34s\n",
            "269:\tlearn: 0.5910619\ttotal: 35s\tremaining: 1m 34s\n",
            "270:\tlearn: 0.5909146\ttotal: 35.1s\tremaining: 1m 34s\n",
            "271:\tlearn: 0.5908861\ttotal: 35.2s\tremaining: 1m 34s\n",
            "272:\tlearn: 0.5908687\ttotal: 35.2s\tremaining: 1m 33s\n",
            "273:\tlearn: 0.5907598\ttotal: 35.3s\tremaining: 1m 33s\n",
            "274:\tlearn: 0.5905190\ttotal: 35.4s\tremaining: 1m 33s\n",
            "275:\tlearn: 0.5904837\ttotal: 35.5s\tremaining: 1m 33s\n",
            "276:\tlearn: 0.5902504\ttotal: 35.6s\tremaining: 1m 32s\n",
            "277:\tlearn: 0.5901177\ttotal: 35.6s\tremaining: 1m 32s\n",
            "278:\tlearn: 0.5899531\ttotal: 35.7s\tremaining: 1m 32s\n",
            "279:\tlearn: 0.5896524\ttotal: 35.9s\tremaining: 1m 32s\n",
            "280:\tlearn: 0.5896084\ttotal: 35.9s\tremaining: 1m 31s\n",
            "281:\tlearn: 0.5894515\ttotal: 36s\tremaining: 1m 31s\n",
            "282:\tlearn: 0.5891137\ttotal: 36.1s\tremaining: 1m 31s\n",
            "283:\tlearn: 0.5888607\ttotal: 36.2s\tremaining: 1m 31s\n",
            "284:\tlearn: 0.5885608\ttotal: 36.3s\tremaining: 1m 31s\n",
            "285:\tlearn: 0.5884782\ttotal: 36.4s\tremaining: 1m 30s\n",
            "286:\tlearn: 0.5883479\ttotal: 36.4s\tremaining: 1m 30s\n",
            "287:\tlearn: 0.5882464\ttotal: 36.5s\tremaining: 1m 30s\n",
            "288:\tlearn: 0.5881108\ttotal: 36.6s\tremaining: 1m 30s\n",
            "289:\tlearn: 0.5879619\ttotal: 36.7s\tremaining: 1m 29s\n",
            "290:\tlearn: 0.5879460\ttotal: 36.8s\tremaining: 1m 29s\n",
            "291:\tlearn: 0.5876568\ttotal: 36.9s\tremaining: 1m 29s\n",
            "292:\tlearn: 0.5874734\ttotal: 37s\tremaining: 1m 29s\n",
            "293:\tlearn: 0.5872512\ttotal: 37.1s\tremaining: 1m 28s\n",
            "294:\tlearn: 0.5870301\ttotal: 37.2s\tremaining: 1m 28s\n",
            "295:\tlearn: 0.5869616\ttotal: 37.2s\tremaining: 1m 28s\n",
            "296:\tlearn: 0.5869307\ttotal: 37.3s\tremaining: 1m 28s\n",
            "297:\tlearn: 0.5869083\ttotal: 37.4s\tremaining: 1m 28s\n",
            "298:\tlearn: 0.5868982\ttotal: 37.5s\tremaining: 1m 27s\n",
            "299:\tlearn: 0.5866341\ttotal: 37.6s\tremaining: 1m 27s\n",
            "300:\tlearn: 0.5864501\ttotal: 37.6s\tremaining: 1m 27s\n",
            "301:\tlearn: 0.5863181\ttotal: 37.7s\tremaining: 1m 27s\n",
            "302:\tlearn: 0.5862579\ttotal: 37.8s\tremaining: 1m 26s\n",
            "303:\tlearn: 0.5859115\ttotal: 37.9s\tremaining: 1m 26s\n",
            "304:\tlearn: 0.5856949\ttotal: 38s\tremaining: 1m 26s\n",
            "305:\tlearn: 0.5854922\ttotal: 38.1s\tremaining: 1m 26s\n",
            "306:\tlearn: 0.5853516\ttotal: 38.2s\tremaining: 1m 26s\n",
            "307:\tlearn: 0.5852900\ttotal: 38.3s\tremaining: 1m 26s\n",
            "308:\tlearn: 0.5849934\ttotal: 38.4s\tremaining: 1m 25s\n",
            "309:\tlearn: 0.5849266\ttotal: 38.6s\tremaining: 1m 25s\n",
            "310:\tlearn: 0.5846923\ttotal: 38.7s\tremaining: 1m 25s\n",
            "311:\tlearn: 0.5846110\ttotal: 38.8s\tremaining: 1m 25s\n",
            "312:\tlearn: 0.5844529\ttotal: 39s\tremaining: 1m 25s\n",
            "313:\tlearn: 0.5844262\ttotal: 39.2s\tremaining: 1m 25s\n",
            "314:\tlearn: 0.5844139\ttotal: 39.3s\tremaining: 1m 25s\n",
            "315:\tlearn: 0.5842878\ttotal: 39.5s\tremaining: 1m 25s\n",
            "316:\tlearn: 0.5842272\ttotal: 39.6s\tremaining: 1m 25s\n",
            "317:\tlearn: 0.5839456\ttotal: 39.8s\tremaining: 1m 25s\n",
            "318:\tlearn: 0.5837681\ttotal: 39.9s\tremaining: 1m 25s\n",
            "319:\tlearn: 0.5836665\ttotal: 40.1s\tremaining: 1m 25s\n",
            "320:\tlearn: 0.5834861\ttotal: 40.3s\tremaining: 1m 25s\n",
            "321:\tlearn: 0.5834005\ttotal: 40.5s\tremaining: 1m 25s\n",
            "322:\tlearn: 0.5833372\ttotal: 40.7s\tremaining: 1m 25s\n",
            "323:\tlearn: 0.5832022\ttotal: 41s\tremaining: 1m 25s\n",
            "324:\tlearn: 0.5829793\ttotal: 41.2s\tremaining: 1m 25s\n",
            "325:\tlearn: 0.5829362\ttotal: 41.3s\tremaining: 1m 25s\n",
            "326:\tlearn: 0.5824741\ttotal: 41.6s\tremaining: 1m 25s\n",
            "327:\tlearn: 0.5823418\ttotal: 41.7s\tremaining: 1m 25s\n",
            "328:\tlearn: 0.5822653\ttotal: 41.9s\tremaining: 1m 25s\n",
            "329:\tlearn: 0.5822199\ttotal: 41.9s\tremaining: 1m 25s\n",
            "330:\tlearn: 0.5818579\ttotal: 42.1s\tremaining: 1m 25s\n",
            "331:\tlearn: 0.5817434\ttotal: 42.2s\tremaining: 1m 24s\n",
            "332:\tlearn: 0.5816530\ttotal: 42.3s\tremaining: 1m 24s\n",
            "333:\tlearn: 0.5816129\ttotal: 42.4s\tremaining: 1m 24s\n",
            "334:\tlearn: 0.5815984\ttotal: 42.5s\tremaining: 1m 24s\n",
            "335:\tlearn: 0.5814538\ttotal: 42.6s\tremaining: 1m 24s\n",
            "336:\tlearn: 0.5812060\ttotal: 42.7s\tremaining: 1m 23s\n",
            "337:\tlearn: 0.5808337\ttotal: 42.8s\tremaining: 1m 23s\n",
            "338:\tlearn: 0.5806719\ttotal: 42.9s\tremaining: 1m 23s\n",
            "339:\tlearn: 0.5805350\ttotal: 43s\tremaining: 1m 23s\n",
            "340:\tlearn: 0.5805213\ttotal: 43.1s\tremaining: 1m 23s\n",
            "341:\tlearn: 0.5804960\ttotal: 43.2s\tremaining: 1m 23s\n",
            "342:\tlearn: 0.5803779\ttotal: 43.3s\tremaining: 1m 22s\n",
            "343:\tlearn: 0.5803493\ttotal: 43.4s\tremaining: 1m 22s\n",
            "344:\tlearn: 0.5803139\ttotal: 43.5s\tremaining: 1m 22s\n",
            "345:\tlearn: 0.5799881\ttotal: 43.6s\tremaining: 1m 22s\n",
            "346:\tlearn: 0.5799323\ttotal: 43.7s\tremaining: 1m 22s\n",
            "347:\tlearn: 0.5798820\ttotal: 43.8s\tremaining: 1m 22s\n",
            "348:\tlearn: 0.5798482\ttotal: 43.9s\tremaining: 1m 21s\n",
            "349:\tlearn: 0.5794481\ttotal: 44s\tremaining: 1m 21s\n",
            "350:\tlearn: 0.5794256\ttotal: 44.1s\tremaining: 1m 21s\n",
            "351:\tlearn: 0.5793113\ttotal: 44.2s\tremaining: 1m 21s\n",
            "352:\tlearn: 0.5791999\ttotal: 44.3s\tremaining: 1m 21s\n",
            "353:\tlearn: 0.5791319\ttotal: 44.4s\tremaining: 1m 21s\n",
            "354:\tlearn: 0.5790252\ttotal: 44.5s\tremaining: 1m 20s\n",
            "355:\tlearn: 0.5789062\ttotal: 44.6s\tremaining: 1m 20s\n",
            "356:\tlearn: 0.5788589\ttotal: 44.7s\tremaining: 1m 20s\n",
            "357:\tlearn: 0.5788343\ttotal: 44.7s\tremaining: 1m 20s\n",
            "358:\tlearn: 0.5786647\ttotal: 44.8s\tremaining: 1m 20s\n",
            "359:\tlearn: 0.5784946\ttotal: 44.9s\tremaining: 1m 19s\n",
            "360:\tlearn: 0.5782428\ttotal: 45s\tremaining: 1m 19s\n",
            "361:\tlearn: 0.5780540\ttotal: 45.1s\tremaining: 1m 19s\n",
            "362:\tlearn: 0.5779153\ttotal: 45.2s\tremaining: 1m 19s\n",
            "363:\tlearn: 0.5775881\ttotal: 45.3s\tremaining: 1m 19s\n",
            "364:\tlearn: 0.5770572\ttotal: 45.4s\tremaining: 1m 19s\n",
            "365:\tlearn: 0.5770457\ttotal: 45.5s\tremaining: 1m 18s\n",
            "366:\tlearn: 0.5769757\ttotal: 45.6s\tremaining: 1m 18s\n",
            "367:\tlearn: 0.5768743\ttotal: 45.7s\tremaining: 1m 18s\n",
            "368:\tlearn: 0.5768463\ttotal: 45.8s\tremaining: 1m 18s\n",
            "369:\tlearn: 0.5767059\ttotal: 45.9s\tremaining: 1m 18s\n",
            "370:\tlearn: 0.5766765\ttotal: 45.9s\tremaining: 1m 17s\n",
            "371:\tlearn: 0.5766590\ttotal: 46s\tremaining: 1m 17s\n",
            "372:\tlearn: 0.5766022\ttotal: 46.1s\tremaining: 1m 17s\n",
            "373:\tlearn: 0.5765755\ttotal: 46.2s\tremaining: 1m 17s\n",
            "374:\tlearn: 0.5765219\ttotal: 46.3s\tremaining: 1m 17s\n",
            "375:\tlearn: 0.5765117\ttotal: 46.3s\tremaining: 1m 16s\n",
            "376:\tlearn: 0.5763258\ttotal: 46.5s\tremaining: 1m 16s\n",
            "377:\tlearn: 0.5762523\ttotal: 46.6s\tremaining: 1m 16s\n",
            "378:\tlearn: 0.5761015\ttotal: 46.7s\tremaining: 1m 16s\n",
            "379:\tlearn: 0.5757860\ttotal: 46.8s\tremaining: 1m 16s\n",
            "380:\tlearn: 0.5757443\ttotal: 46.9s\tremaining: 1m 16s\n",
            "381:\tlearn: 0.5753717\ttotal: 47s\tremaining: 1m 15s\n",
            "382:\tlearn: 0.5752716\ttotal: 47s\tremaining: 1m 15s\n",
            "383:\tlearn: 0.5750703\ttotal: 47.1s\tremaining: 1m 15s\n",
            "384:\tlearn: 0.5750404\ttotal: 47.2s\tremaining: 1m 15s\n",
            "385:\tlearn: 0.5750061\ttotal: 47.3s\tremaining: 1m 15s\n",
            "386:\tlearn: 0.5749951\ttotal: 47.4s\tremaining: 1m 15s\n",
            "387:\tlearn: 0.5748120\ttotal: 47.4s\tremaining: 1m 14s\n",
            "388:\tlearn: 0.5746716\ttotal: 47.6s\tremaining: 1m 14s\n",
            "389:\tlearn: 0.5744975\ttotal: 47.6s\tremaining: 1m 14s\n",
            "390:\tlearn: 0.5744142\ttotal: 47.7s\tremaining: 1m 14s\n",
            "391:\tlearn: 0.5740852\ttotal: 47.8s\tremaining: 1m 14s\n",
            "392:\tlearn: 0.5739515\ttotal: 47.9s\tremaining: 1m 13s\n",
            "393:\tlearn: 0.5738180\ttotal: 48s\tremaining: 1m 13s\n",
            "394:\tlearn: 0.5738075\ttotal: 48.1s\tremaining: 1m 13s\n",
            "395:\tlearn: 0.5735919\ttotal: 48.1s\tremaining: 1m 13s\n",
            "396:\tlearn: 0.5734994\ttotal: 48.2s\tremaining: 1m 13s\n",
            "397:\tlearn: 0.5734133\ttotal: 48.3s\tremaining: 1m 13s\n",
            "398:\tlearn: 0.5731486\ttotal: 48.4s\tremaining: 1m 12s\n",
            "399:\tlearn: 0.5731122\ttotal: 48.5s\tremaining: 1m 12s\n",
            "400:\tlearn: 0.5729811\ttotal: 48.6s\tremaining: 1m 12s\n",
            "401:\tlearn: 0.5729321\ttotal: 48.7s\tremaining: 1m 12s\n",
            "402:\tlearn: 0.5728989\ttotal: 48.8s\tremaining: 1m 12s\n",
            "403:\tlearn: 0.5727033\ttotal: 48.8s\tremaining: 1m 12s\n",
            "404:\tlearn: 0.5726774\ttotal: 48.9s\tremaining: 1m 11s\n",
            "405:\tlearn: 0.5726678\ttotal: 49s\tremaining: 1m 11s\n",
            "406:\tlearn: 0.5726124\ttotal: 49.1s\tremaining: 1m 11s\n",
            "407:\tlearn: 0.5724681\ttotal: 49.1s\tremaining: 1m 11s\n",
            "408:\tlearn: 0.5723665\ttotal: 49.2s\tremaining: 1m 11s\n",
            "409:\tlearn: 0.5722130\ttotal: 49.3s\tremaining: 1m 10s\n",
            "410:\tlearn: 0.5720988\ttotal: 49.4s\tremaining: 1m 10s\n",
            "411:\tlearn: 0.5720287\ttotal: 49.5s\tremaining: 1m 10s\n",
            "412:\tlearn: 0.5716474\ttotal: 49.6s\tremaining: 1m 10s\n",
            "413:\tlearn: 0.5716130\ttotal: 49.7s\tremaining: 1m 10s\n",
            "414:\tlearn: 0.5715644\ttotal: 49.7s\tremaining: 1m 10s\n",
            "415:\tlearn: 0.5714087\ttotal: 49.8s\tremaining: 1m 9s\n",
            "416:\tlearn: 0.5713106\ttotal: 49.9s\tremaining: 1m 9s\n",
            "417:\tlearn: 0.5712575\ttotal: 50s\tremaining: 1m 9s\n",
            "418:\tlearn: 0.5710709\ttotal: 50.1s\tremaining: 1m 9s\n",
            "419:\tlearn: 0.5707300\ttotal: 50.1s\tremaining: 1m 9s\n",
            "420:\tlearn: 0.5706469\ttotal: 50.2s\tremaining: 1m 9s\n",
            "421:\tlearn: 0.5706337\ttotal: 50.3s\tremaining: 1m 8s\n",
            "422:\tlearn: 0.5704961\ttotal: 50.4s\tremaining: 1m 8s\n",
            "423:\tlearn: 0.5703941\ttotal: 50.5s\tremaining: 1m 8s\n",
            "424:\tlearn: 0.5702450\ttotal: 50.5s\tremaining: 1m 8s\n",
            "425:\tlearn: 0.5700936\ttotal: 50.6s\tremaining: 1m 8s\n",
            "426:\tlearn: 0.5700801\ttotal: 50.7s\tremaining: 1m 8s\n",
            "427:\tlearn: 0.5700001\ttotal: 50.8s\tremaining: 1m 7s\n",
            "428:\tlearn: 0.5699137\ttotal: 50.9s\tremaining: 1m 7s\n",
            "429:\tlearn: 0.5698414\ttotal: 50.9s\tremaining: 1m 7s\n",
            "430:\tlearn: 0.5696728\ttotal: 51s\tremaining: 1m 7s\n",
            "431:\tlearn: 0.5696190\ttotal: 51.1s\tremaining: 1m 7s\n",
            "432:\tlearn: 0.5695779\ttotal: 51.2s\tremaining: 1m 7s\n",
            "433:\tlearn: 0.5695060\ttotal: 51.3s\tremaining: 1m 6s\n",
            "434:\tlearn: 0.5693286\ttotal: 51.4s\tremaining: 1m 6s\n",
            "435:\tlearn: 0.5693121\ttotal: 51.4s\tremaining: 1m 6s\n",
            "436:\tlearn: 0.5692020\ttotal: 51.5s\tremaining: 1m 6s\n",
            "437:\tlearn: 0.5691394\ttotal: 51.6s\tremaining: 1m 6s\n",
            "438:\tlearn: 0.5690950\ttotal: 51.7s\tremaining: 1m 6s\n",
            "439:\tlearn: 0.5689093\ttotal: 51.8s\tremaining: 1m 5s\n",
            "440:\tlearn: 0.5688061\ttotal: 52s\tremaining: 1m 5s\n",
            "441:\tlearn: 0.5687956\ttotal: 52.1s\tremaining: 1m 5s\n",
            "442:\tlearn: 0.5687599\ttotal: 52.3s\tremaining: 1m 5s\n",
            "443:\tlearn: 0.5685285\ttotal: 52.4s\tremaining: 1m 5s\n",
            "444:\tlearn: 0.5685116\ttotal: 52.6s\tremaining: 1m 5s\n",
            "445:\tlearn: 0.5684800\ttotal: 52.8s\tremaining: 1m 5s\n",
            "446:\tlearn: 0.5684613\ttotal: 52.9s\tremaining: 1m 5s\n",
            "447:\tlearn: 0.5683248\ttotal: 53s\tremaining: 1m 5s\n",
            "448:\tlearn: 0.5680301\ttotal: 53.2s\tremaining: 1m 5s\n",
            "449:\tlearn: 0.5679699\ttotal: 53.4s\tremaining: 1m 5s\n",
            "450:\tlearn: 0.5677874\ttotal: 53.5s\tremaining: 1m 5s\n",
            "451:\tlearn: 0.5677785\ttotal: 53.7s\tremaining: 1m 5s\n",
            "452:\tlearn: 0.5677335\ttotal: 53.8s\tremaining: 1m 4s\n",
            "453:\tlearn: 0.5674880\ttotal: 54s\tremaining: 1m 4s\n",
            "454:\tlearn: 0.5674237\ttotal: 54.2s\tremaining: 1m 4s\n",
            "455:\tlearn: 0.5671752\ttotal: 54.3s\tremaining: 1m 4s\n",
            "456:\tlearn: 0.5670038\ttotal: 54.5s\tremaining: 1m 4s\n",
            "457:\tlearn: 0.5668663\ttotal: 54.6s\tremaining: 1m 4s\n",
            "458:\tlearn: 0.5667357\ttotal: 54.8s\tremaining: 1m 4s\n",
            "459:\tlearn: 0.5666882\ttotal: 54.8s\tremaining: 1m 4s\n",
            "460:\tlearn: 0.5665878\ttotal: 54.9s\tremaining: 1m 4s\n",
            "461:\tlearn: 0.5664837\ttotal: 55s\tremaining: 1m 4s\n",
            "462:\tlearn: 0.5661968\ttotal: 55.1s\tremaining: 1m 3s\n",
            "463:\tlearn: 0.5659567\ttotal: 55.2s\tremaining: 1m 3s\n",
            "464:\tlearn: 0.5659120\ttotal: 55.3s\tremaining: 1m 3s\n",
            "465:\tlearn: 0.5659063\ttotal: 55.4s\tremaining: 1m 3s\n",
            "466:\tlearn: 0.5658391\ttotal: 55.4s\tremaining: 1m 3s\n",
            "467:\tlearn: 0.5654643\ttotal: 55.5s\tremaining: 1m 3s\n",
            "468:\tlearn: 0.5653877\ttotal: 55.6s\tremaining: 1m 2s\n",
            "469:\tlearn: 0.5653070\ttotal: 55.7s\tremaining: 1m 2s\n",
            "470:\tlearn: 0.5651680\ttotal: 55.8s\tremaining: 1m 2s\n",
            "471:\tlearn: 0.5648630\ttotal: 55.9s\tremaining: 1m 2s\n",
            "472:\tlearn: 0.5647170\ttotal: 56s\tremaining: 1m 2s\n",
            "473:\tlearn: 0.5646785\ttotal: 56.1s\tremaining: 1m 2s\n",
            "474:\tlearn: 0.5646612\ttotal: 56.1s\tremaining: 1m 2s\n",
            "475:\tlearn: 0.5644342\ttotal: 56.2s\tremaining: 1m 1s\n",
            "476:\tlearn: 0.5644132\ttotal: 56.3s\tremaining: 1m 1s\n",
            "477:\tlearn: 0.5643736\ttotal: 56.4s\tremaining: 1m 1s\n",
            "478:\tlearn: 0.5642394\ttotal: 56.5s\tremaining: 1m 1s\n",
            "479:\tlearn: 0.5641161\ttotal: 56.6s\tremaining: 1m 1s\n",
            "480:\tlearn: 0.5639102\ttotal: 56.6s\tremaining: 1m 1s\n",
            "481:\tlearn: 0.5638702\ttotal: 56.7s\tremaining: 1m\n",
            "482:\tlearn: 0.5638552\ttotal: 56.8s\tremaining: 1m\n",
            "483:\tlearn: 0.5636616\ttotal: 56.9s\tremaining: 1m\n",
            "484:\tlearn: 0.5635936\ttotal: 57s\tremaining: 1m\n",
            "485:\tlearn: 0.5633711\ttotal: 57.1s\tremaining: 1m\n",
            "486:\tlearn: 0.5632662\ttotal: 57.1s\tremaining: 1m\n",
            "487:\tlearn: 0.5632289\ttotal: 57.2s\tremaining: 1m\n",
            "488:\tlearn: 0.5631608\ttotal: 57.3s\tremaining: 59.9s\n",
            "489:\tlearn: 0.5630212\ttotal: 57.4s\tremaining: 59.7s\n",
            "490:\tlearn: 0.5629441\ttotal: 57.5s\tremaining: 59.6s\n",
            "491:\tlearn: 0.5629141\ttotal: 57.6s\tremaining: 59.4s\n",
            "492:\tlearn: 0.5626099\ttotal: 57.7s\tremaining: 59.3s\n",
            "493:\tlearn: 0.5622969\ttotal: 57.8s\tremaining: 59.2s\n",
            "494:\tlearn: 0.5622786\ttotal: 57.8s\tremaining: 59s\n",
            "495:\tlearn: 0.5620879\ttotal: 57.9s\tremaining: 58.9s\n",
            "496:\tlearn: 0.5620653\ttotal: 58s\tremaining: 58.7s\n",
            "497:\tlearn: 0.5620379\ttotal: 58.1s\tremaining: 58.6s\n",
            "498:\tlearn: 0.5618855\ttotal: 58.2s\tremaining: 58.4s\n",
            "499:\tlearn: 0.5618041\ttotal: 58.3s\tremaining: 58.3s\n",
            "500:\tlearn: 0.5615531\ttotal: 58.4s\tremaining: 58.1s\n",
            "501:\tlearn: 0.5613420\ttotal: 58.5s\tremaining: 58s\n",
            "502:\tlearn: 0.5611399\ttotal: 58.6s\tremaining: 57.9s\n",
            "503:\tlearn: 0.5610517\ttotal: 58.6s\tremaining: 57.7s\n",
            "504:\tlearn: 0.5609345\ttotal: 58.7s\tremaining: 57.6s\n",
            "505:\tlearn: 0.5609249\ttotal: 58.8s\tremaining: 57.4s\n",
            "506:\tlearn: 0.5608639\ttotal: 58.9s\tremaining: 57.2s\n",
            "507:\tlearn: 0.5605526\ttotal: 59s\tremaining: 57.1s\n",
            "508:\tlearn: 0.5605325\ttotal: 59s\tremaining: 56.9s\n",
            "509:\tlearn: 0.5602993\ttotal: 59.1s\tremaining: 56.8s\n",
            "510:\tlearn: 0.5600563\ttotal: 59.2s\tremaining: 56.7s\n",
            "511:\tlearn: 0.5600468\ttotal: 59.3s\tremaining: 56.5s\n",
            "512:\tlearn: 0.5600341\ttotal: 59.4s\tremaining: 56.4s\n",
            "513:\tlearn: 0.5598184\ttotal: 59.5s\tremaining: 56.2s\n",
            "514:\tlearn: 0.5596904\ttotal: 59.6s\tremaining: 56.1s\n",
            "515:\tlearn: 0.5596179\ttotal: 59.6s\tremaining: 55.9s\n",
            "516:\tlearn: 0.5595104\ttotal: 59.7s\tremaining: 55.8s\n",
            "517:\tlearn: 0.5593031\ttotal: 59.8s\tremaining: 55.7s\n",
            "518:\tlearn: 0.5592099\ttotal: 59.9s\tremaining: 55.5s\n",
            "519:\tlearn: 0.5591791\ttotal: 60s\tremaining: 55.4s\n",
            "520:\tlearn: 0.5591158\ttotal: 1m\tremaining: 55.2s\n",
            "521:\tlearn: 0.5590170\ttotal: 1m\tremaining: 55.1s\n",
            "522:\tlearn: 0.5589500\ttotal: 1m\tremaining: 55s\n",
            "523:\tlearn: 0.5589273\ttotal: 1m\tremaining: 54.8s\n",
            "524:\tlearn: 0.5586886\ttotal: 1m\tremaining: 54.7s\n",
            "525:\tlearn: 0.5585803\ttotal: 1m\tremaining: 54.5s\n",
            "526:\tlearn: 0.5584356\ttotal: 1m\tremaining: 54.4s\n",
            "527:\tlearn: 0.5583874\ttotal: 1m\tremaining: 54.2s\n",
            "528:\tlearn: 0.5582865\ttotal: 1m\tremaining: 54.1s\n",
            "529:\tlearn: 0.5581519\ttotal: 1m\tremaining: 54s\n",
            "530:\tlearn: 0.5580448\ttotal: 1m\tremaining: 53.8s\n",
            "531:\tlearn: 0.5578894\ttotal: 1m 1s\tremaining: 53.7s\n",
            "532:\tlearn: 0.5577078\ttotal: 1m 1s\tremaining: 53.5s\n",
            "533:\tlearn: 0.5576344\ttotal: 1m 1s\tremaining: 53.4s\n",
            "534:\tlearn: 0.5574956\ttotal: 1m 1s\tremaining: 53.3s\n",
            "535:\tlearn: 0.5574784\ttotal: 1m 1s\tremaining: 53.1s\n",
            "536:\tlearn: 0.5573658\ttotal: 1m 1s\tremaining: 53s\n",
            "537:\tlearn: 0.5573557\ttotal: 1m 1s\tremaining: 52.9s\n",
            "538:\tlearn: 0.5571450\ttotal: 1m 1s\tremaining: 52.7s\n",
            "539:\tlearn: 0.5571093\ttotal: 1m 1s\tremaining: 52.6s\n",
            "540:\tlearn: 0.5570424\ttotal: 1m 1s\tremaining: 52.4s\n",
            "541:\tlearn: 0.5570031\ttotal: 1m 1s\tremaining: 52.3s\n",
            "542:\tlearn: 0.5569883\ttotal: 1m 1s\tremaining: 52.1s\n",
            "543:\tlearn: 0.5569058\ttotal: 1m 2s\tremaining: 52s\n",
            "544:\tlearn: 0.5568917\ttotal: 1m 2s\tremaining: 51.9s\n",
            "545:\tlearn: 0.5567418\ttotal: 1m 2s\tremaining: 51.7s\n",
            "546:\tlearn: 0.5567242\ttotal: 1m 2s\tremaining: 51.6s\n",
            "547:\tlearn: 0.5565958\ttotal: 1m 2s\tremaining: 51.4s\n",
            "548:\tlearn: 0.5564573\ttotal: 1m 2s\tremaining: 51.3s\n",
            "549:\tlearn: 0.5563319\ttotal: 1m 2s\tremaining: 51.2s\n",
            "550:\tlearn: 0.5563027\ttotal: 1m 2s\tremaining: 51s\n",
            "551:\tlearn: 0.5561604\ttotal: 1m 2s\tremaining: 50.9s\n",
            "552:\tlearn: 0.5561257\ttotal: 1m 2s\tremaining: 50.7s\n",
            "553:\tlearn: 0.5558956\ttotal: 1m 2s\tremaining: 50.6s\n",
            "554:\tlearn: 0.5556556\ttotal: 1m 2s\tremaining: 50.5s\n",
            "555:\tlearn: 0.5555326\ttotal: 1m 3s\tremaining: 50.4s\n",
            "556:\tlearn: 0.5551606\ttotal: 1m 3s\tremaining: 50.2s\n",
            "557:\tlearn: 0.5550721\ttotal: 1m 3s\tremaining: 50.1s\n",
            "558:\tlearn: 0.5547999\ttotal: 1m 3s\tremaining: 50s\n",
            "559:\tlearn: 0.5546942\ttotal: 1m 3s\tremaining: 49.8s\n",
            "560:\tlearn: 0.5545525\ttotal: 1m 3s\tremaining: 49.7s\n",
            "561:\tlearn: 0.5543244\ttotal: 1m 3s\tremaining: 49.6s\n",
            "562:\tlearn: 0.5541196\ttotal: 1m 3s\tremaining: 49.4s\n",
            "563:\tlearn: 0.5539931\ttotal: 1m 3s\tremaining: 49.3s\n",
            "564:\tlearn: 0.5536039\ttotal: 1m 3s\tremaining: 49.2s\n",
            "565:\tlearn: 0.5535670\ttotal: 1m 3s\tremaining: 49s\n",
            "566:\tlearn: 0.5535180\ttotal: 1m 4s\tremaining: 48.9s\n",
            "567:\tlearn: 0.5533596\ttotal: 1m 4s\tremaining: 48.8s\n",
            "568:\tlearn: 0.5532721\ttotal: 1m 4s\tremaining: 48.6s\n",
            "569:\tlearn: 0.5532400\ttotal: 1m 4s\tremaining: 48.5s\n",
            "570:\tlearn: 0.5530169\ttotal: 1m 4s\tremaining: 48.4s\n",
            "571:\tlearn: 0.5527337\ttotal: 1m 4s\tremaining: 48.3s\n",
            "572:\tlearn: 0.5526411\ttotal: 1m 4s\tremaining: 48.1s\n",
            "573:\tlearn: 0.5523342\ttotal: 1m 4s\tremaining: 48s\n",
            "574:\tlearn: 0.5521137\ttotal: 1m 4s\tremaining: 47.9s\n",
            "575:\tlearn: 0.5517365\ttotal: 1m 4s\tremaining: 47.8s\n",
            "576:\tlearn: 0.5516753\ttotal: 1m 5s\tremaining: 47.7s\n",
            "577:\tlearn: 0.5515441\ttotal: 1m 5s\tremaining: 47.6s\n",
            "578:\tlearn: 0.5513349\ttotal: 1m 5s\tremaining: 47.5s\n",
            "579:\tlearn: 0.5513078\ttotal: 1m 5s\tremaining: 47.4s\n",
            "580:\tlearn: 0.5511620\ttotal: 1m 5s\tremaining: 47.4s\n",
            "581:\tlearn: 0.5508765\ttotal: 1m 5s\tremaining: 47.3s\n",
            "582:\tlearn: 0.5508135\ttotal: 1m 5s\tremaining: 47.2s\n",
            "583:\tlearn: 0.5503992\ttotal: 1m 6s\tremaining: 47.1s\n",
            "584:\tlearn: 0.5503678\ttotal: 1m 6s\tremaining: 47s\n",
            "585:\tlearn: 0.5502599\ttotal: 1m 6s\tremaining: 47s\n",
            "586:\tlearn: 0.5502118\ttotal: 1m 6s\tremaining: 46.9s\n",
            "587:\tlearn: 0.5499602\ttotal: 1m 6s\tremaining: 46.8s\n",
            "588:\tlearn: 0.5498017\ttotal: 1m 6s\tremaining: 46.7s\n",
            "589:\tlearn: 0.5496191\ttotal: 1m 7s\tremaining: 46.6s\n",
            "590:\tlearn: 0.5494999\ttotal: 1m 7s\tremaining: 46.5s\n",
            "591:\tlearn: 0.5493769\ttotal: 1m 7s\tremaining: 46.4s\n",
            "592:\tlearn: 0.5492415\ttotal: 1m 7s\tremaining: 46.4s\n",
            "593:\tlearn: 0.5491774\ttotal: 1m 7s\tremaining: 46.3s\n",
            "594:\tlearn: 0.5490929\ttotal: 1m 7s\tremaining: 46.2s\n",
            "595:\tlearn: 0.5490852\ttotal: 1m 7s\tremaining: 46s\n",
            "596:\tlearn: 0.5490331\ttotal: 1m 8s\tremaining: 45.9s\n",
            "597:\tlearn: 0.5488303\ttotal: 1m 8s\tremaining: 45.8s\n",
            "598:\tlearn: 0.5487603\ttotal: 1m 8s\tremaining: 45.6s\n",
            "599:\tlearn: 0.5486041\ttotal: 1m 8s\tremaining: 45.5s\n",
            "600:\tlearn: 0.5485568\ttotal: 1m 8s\tremaining: 45.4s\n",
            "601:\tlearn: 0.5483714\ttotal: 1m 8s\tremaining: 45.3s\n",
            "602:\tlearn: 0.5481866\ttotal: 1m 8s\tremaining: 45.1s\n",
            "603:\tlearn: 0.5480940\ttotal: 1m 8s\tremaining: 45s\n",
            "604:\tlearn: 0.5479836\ttotal: 1m 8s\tremaining: 44.9s\n",
            "605:\tlearn: 0.5477138\ttotal: 1m 8s\tremaining: 44.8s\n",
            "606:\tlearn: 0.5477025\ttotal: 1m 8s\tremaining: 44.6s\n",
            "607:\tlearn: 0.5475534\ttotal: 1m 8s\tremaining: 44.5s\n",
            "608:\tlearn: 0.5472572\ttotal: 1m 9s\tremaining: 44.4s\n",
            "609:\tlearn: 0.5469302\ttotal: 1m 9s\tremaining: 44.2s\n",
            "610:\tlearn: 0.5467506\ttotal: 1m 9s\tremaining: 44.1s\n",
            "611:\tlearn: 0.5467113\ttotal: 1m 9s\tremaining: 44s\n",
            "612:\tlearn: 0.5466090\ttotal: 1m 9s\tremaining: 43.8s\n",
            "613:\tlearn: 0.5462041\ttotal: 1m 9s\tremaining: 43.7s\n",
            "614:\tlearn: 0.5459648\ttotal: 1m 9s\tremaining: 43.6s\n",
            "615:\tlearn: 0.5458472\ttotal: 1m 9s\tremaining: 43.5s\n",
            "616:\tlearn: 0.5458230\ttotal: 1m 9s\tremaining: 43.3s\n",
            "617:\tlearn: 0.5456408\ttotal: 1m 9s\tremaining: 43.2s\n",
            "618:\tlearn: 0.5455915\ttotal: 1m 9s\tremaining: 43.1s\n",
            "619:\tlearn: 0.5453110\ttotal: 1m 10s\tremaining: 43s\n",
            "620:\tlearn: 0.5452538\ttotal: 1m 10s\tremaining: 42.8s\n",
            "621:\tlearn: 0.5452098\ttotal: 1m 10s\tremaining: 42.7s\n",
            "622:\tlearn: 0.5449540\ttotal: 1m 10s\tremaining: 42.6s\n",
            "623:\tlearn: 0.5448803\ttotal: 1m 10s\tremaining: 42.4s\n",
            "624:\tlearn: 0.5448715\ttotal: 1m 10s\tremaining: 42.3s\n",
            "625:\tlearn: 0.5447896\ttotal: 1m 10s\tremaining: 42.2s\n",
            "626:\tlearn: 0.5446620\ttotal: 1m 10s\tremaining: 42.1s\n",
            "627:\tlearn: 0.5446298\ttotal: 1m 10s\tremaining: 41.9s\n",
            "628:\tlearn: 0.5444908\ttotal: 1m 10s\tremaining: 41.8s\n",
            "629:\tlearn: 0.5441699\ttotal: 1m 10s\tremaining: 41.7s\n",
            "630:\tlearn: 0.5440706\ttotal: 1m 11s\tremaining: 41.5s\n",
            "631:\tlearn: 0.5437663\ttotal: 1m 11s\tremaining: 41.4s\n",
            "632:\tlearn: 0.5436408\ttotal: 1m 11s\tremaining: 41.3s\n",
            "633:\tlearn: 0.5434661\ttotal: 1m 11s\tremaining: 41.2s\n",
            "634:\tlearn: 0.5433435\ttotal: 1m 11s\tremaining: 41s\n",
            "635:\tlearn: 0.5433079\ttotal: 1m 11s\tremaining: 40.9s\n",
            "636:\tlearn: 0.5432527\ttotal: 1m 11s\tremaining: 40.8s\n",
            "637:\tlearn: 0.5432293\ttotal: 1m 11s\tremaining: 40.6s\n",
            "638:\tlearn: 0.5431871\ttotal: 1m 11s\tremaining: 40.5s\n",
            "639:\tlearn: 0.5431196\ttotal: 1m 11s\tremaining: 40.4s\n",
            "640:\tlearn: 0.5430935\ttotal: 1m 11s\tremaining: 40.3s\n",
            "641:\tlearn: 0.5430079\ttotal: 1m 11s\tremaining: 40.1s\n",
            "642:\tlearn: 0.5429062\ttotal: 1m 12s\tremaining: 40s\n",
            "643:\tlearn: 0.5427630\ttotal: 1m 12s\tremaining: 39.9s\n",
            "644:\tlearn: 0.5427473\ttotal: 1m 12s\tremaining: 39.8s\n",
            "645:\tlearn: 0.5427385\ttotal: 1m 12s\tremaining: 39.6s\n",
            "646:\tlearn: 0.5425649\ttotal: 1m 12s\tremaining: 39.5s\n",
            "647:\tlearn: 0.5423539\ttotal: 1m 12s\tremaining: 39.4s\n",
            "648:\tlearn: 0.5422400\ttotal: 1m 12s\tremaining: 39.3s\n",
            "649:\tlearn: 0.5422161\ttotal: 1m 12s\tremaining: 39.1s\n",
            "650:\tlearn: 0.5421856\ttotal: 1m 12s\tremaining: 39s\n",
            "651:\tlearn: 0.5420420\ttotal: 1m 12s\tremaining: 38.9s\n",
            "652:\tlearn: 0.5417010\ttotal: 1m 12s\tremaining: 38.8s\n",
            "653:\tlearn: 0.5413215\ttotal: 1m 13s\tremaining: 38.6s\n",
            "654:\tlearn: 0.5412663\ttotal: 1m 13s\tremaining: 38.5s\n",
            "655:\tlearn: 0.5410438\ttotal: 1m 13s\tremaining: 38.4s\n",
            "656:\tlearn: 0.5409534\ttotal: 1m 13s\tremaining: 38.3s\n",
            "657:\tlearn: 0.5408729\ttotal: 1m 13s\tremaining: 38.1s\n",
            "658:\tlearn: 0.5407970\ttotal: 1m 13s\tremaining: 38s\n",
            "659:\tlearn: 0.5407331\ttotal: 1m 13s\tremaining: 37.9s\n",
            "660:\tlearn: 0.5406898\ttotal: 1m 13s\tremaining: 37.8s\n",
            "661:\tlearn: 0.5404320\ttotal: 1m 13s\tremaining: 37.6s\n",
            "662:\tlearn: 0.5403756\ttotal: 1m 13s\tremaining: 37.5s\n",
            "663:\tlearn: 0.5401937\ttotal: 1m 13s\tremaining: 37.4s\n",
            "664:\tlearn: 0.5398957\ttotal: 1m 13s\tremaining: 37.3s\n",
            "665:\tlearn: 0.5395411\ttotal: 1m 14s\tremaining: 37.2s\n",
            "666:\tlearn: 0.5395098\ttotal: 1m 14s\tremaining: 37s\n",
            "667:\tlearn: 0.5394518\ttotal: 1m 14s\tremaining: 36.9s\n",
            "668:\tlearn: 0.5394119\ttotal: 1m 14s\tremaining: 36.8s\n",
            "669:\tlearn: 0.5392629\ttotal: 1m 14s\tremaining: 36.7s\n",
            "670:\tlearn: 0.5392558\ttotal: 1m 14s\tremaining: 36.5s\n",
            "671:\tlearn: 0.5391340\ttotal: 1m 14s\tremaining: 36.4s\n",
            "672:\tlearn: 0.5390566\ttotal: 1m 14s\tremaining: 36.3s\n",
            "673:\tlearn: 0.5389231\ttotal: 1m 14s\tremaining: 36.2s\n",
            "674:\tlearn: 0.5388152\ttotal: 1m 14s\tremaining: 36.1s\n",
            "675:\tlearn: 0.5386316\ttotal: 1m 14s\tremaining: 35.9s\n",
            "676:\tlearn: 0.5385715\ttotal: 1m 15s\tremaining: 35.8s\n",
            "677:\tlearn: 0.5382446\ttotal: 1m 15s\tremaining: 35.7s\n",
            "678:\tlearn: 0.5382352\ttotal: 1m 15s\tremaining: 35.6s\n",
            "679:\tlearn: 0.5382157\ttotal: 1m 15s\tremaining: 35.4s\n",
            "680:\tlearn: 0.5381897\ttotal: 1m 15s\tremaining: 35.3s\n",
            "681:\tlearn: 0.5381499\ttotal: 1m 15s\tremaining: 35.2s\n",
            "682:\tlearn: 0.5379880\ttotal: 1m 15s\tremaining: 35.1s\n",
            "683:\tlearn: 0.5379147\ttotal: 1m 15s\tremaining: 34.9s\n",
            "684:\tlearn: 0.5377637\ttotal: 1m 15s\tremaining: 34.8s\n",
            "685:\tlearn: 0.5377396\ttotal: 1m 15s\tremaining: 34.7s\n",
            "686:\tlearn: 0.5375897\ttotal: 1m 15s\tremaining: 34.6s\n",
            "687:\tlearn: 0.5374986\ttotal: 1m 16s\tremaining: 34.5s\n",
            "688:\tlearn: 0.5374872\ttotal: 1m 16s\tremaining: 34.3s\n",
            "689:\tlearn: 0.5374413\ttotal: 1m 16s\tremaining: 34.2s\n",
            "690:\tlearn: 0.5374082\ttotal: 1m 16s\tremaining: 34.1s\n",
            "691:\tlearn: 0.5371426\ttotal: 1m 16s\tremaining: 34s\n",
            "692:\tlearn: 0.5370824\ttotal: 1m 16s\tremaining: 33.9s\n",
            "693:\tlearn: 0.5369914\ttotal: 1m 16s\tremaining: 33.7s\n",
            "694:\tlearn: 0.5368638\ttotal: 1m 16s\tremaining: 33.6s\n",
            "695:\tlearn: 0.5367584\ttotal: 1m 16s\tremaining: 33.5s\n",
            "696:\tlearn: 0.5364189\ttotal: 1m 16s\tremaining: 33.4s\n",
            "697:\tlearn: 0.5362511\ttotal: 1m 16s\tremaining: 33.3s\n",
            "698:\tlearn: 0.5361023\ttotal: 1m 17s\tremaining: 33.2s\n",
            "699:\tlearn: 0.5360037\ttotal: 1m 17s\tremaining: 33s\n",
            "700:\tlearn: 0.5359095\ttotal: 1m 17s\tremaining: 32.9s\n",
            "701:\tlearn: 0.5357958\ttotal: 1m 17s\tremaining: 32.8s\n",
            "702:\tlearn: 0.5357016\ttotal: 1m 17s\tremaining: 32.7s\n",
            "703:\tlearn: 0.5355692\ttotal: 1m 17s\tremaining: 32.6s\n",
            "704:\tlearn: 0.5354662\ttotal: 1m 17s\tremaining: 32.4s\n",
            "705:\tlearn: 0.5353282\ttotal: 1m 17s\tremaining: 32.3s\n",
            "706:\tlearn: 0.5352623\ttotal: 1m 17s\tremaining: 32.2s\n",
            "707:\tlearn: 0.5350185\ttotal: 1m 17s\tremaining: 32.1s\n",
            "708:\tlearn: 0.5348833\ttotal: 1m 17s\tremaining: 32s\n",
            "709:\tlearn: 0.5347825\ttotal: 1m 18s\tremaining: 31.9s\n",
            "710:\tlearn: 0.5346047\ttotal: 1m 18s\tremaining: 31.8s\n",
            "711:\tlearn: 0.5344645\ttotal: 1m 18s\tremaining: 31.7s\n",
            "712:\tlearn: 0.5341792\ttotal: 1m 18s\tremaining: 31.6s\n",
            "713:\tlearn: 0.5340837\ttotal: 1m 18s\tremaining: 31.5s\n",
            "714:\tlearn: 0.5340309\ttotal: 1m 18s\tremaining: 31.4s\n",
            "715:\tlearn: 0.5339950\ttotal: 1m 19s\tremaining: 31.3s\n",
            "716:\tlearn: 0.5338558\ttotal: 1m 19s\tremaining: 31.2s\n",
            "717:\tlearn: 0.5337719\ttotal: 1m 19s\tremaining: 31.1s\n",
            "718:\tlearn: 0.5337405\ttotal: 1m 19s\tremaining: 31s\n",
            "719:\tlearn: 0.5336736\ttotal: 1m 19s\tremaining: 31s\n",
            "720:\tlearn: 0.5332925\ttotal: 1m 19s\tremaining: 30.9s\n",
            "721:\tlearn: 0.5332548\ttotal: 1m 19s\tremaining: 30.8s\n",
            "722:\tlearn: 0.5332266\ttotal: 1m 20s\tremaining: 30.7s\n",
            "723:\tlearn: 0.5331590\ttotal: 1m 20s\tremaining: 30.6s\n",
            "724:\tlearn: 0.5330263\ttotal: 1m 20s\tremaining: 30.5s\n",
            "725:\tlearn: 0.5329988\ttotal: 1m 20s\tremaining: 30.4s\n",
            "726:\tlearn: 0.5328748\ttotal: 1m 20s\tremaining: 30.3s\n",
            "727:\tlearn: 0.5326268\ttotal: 1m 20s\tremaining: 30.2s\n",
            "728:\tlearn: 0.5324850\ttotal: 1m 20s\tremaining: 30.1s\n",
            "729:\tlearn: 0.5323824\ttotal: 1m 21s\tremaining: 30s\n",
            "730:\tlearn: 0.5321891\ttotal: 1m 21s\tremaining: 29.9s\n",
            "731:\tlearn: 0.5321425\ttotal: 1m 21s\tremaining: 29.7s\n",
            "732:\tlearn: 0.5319715\ttotal: 1m 21s\tremaining: 29.6s\n",
            "733:\tlearn: 0.5319383\ttotal: 1m 21s\tremaining: 29.5s\n",
            "734:\tlearn: 0.5318971\ttotal: 1m 21s\tremaining: 29.4s\n",
            "735:\tlearn: 0.5316508\ttotal: 1m 21s\tremaining: 29.3s\n",
            "736:\tlearn: 0.5316254\ttotal: 1m 21s\tremaining: 29.1s\n",
            "737:\tlearn: 0.5315600\ttotal: 1m 21s\tremaining: 29s\n",
            "738:\tlearn: 0.5314066\ttotal: 1m 21s\tremaining: 28.9s\n",
            "739:\tlearn: 0.5313786\ttotal: 1m 21s\tremaining: 28.8s\n",
            "740:\tlearn: 0.5311260\ttotal: 1m 22s\tremaining: 28.7s\n",
            "741:\tlearn: 0.5308188\ttotal: 1m 22s\tremaining: 28.6s\n",
            "742:\tlearn: 0.5303866\ttotal: 1m 22s\tremaining: 28.4s\n",
            "743:\tlearn: 0.5302505\ttotal: 1m 22s\tremaining: 28.3s\n",
            "744:\tlearn: 0.5302199\ttotal: 1m 22s\tremaining: 28.2s\n",
            "745:\tlearn: 0.5301631\ttotal: 1m 22s\tremaining: 28.1s\n",
            "746:\tlearn: 0.5299132\ttotal: 1m 22s\tremaining: 28s\n",
            "747:\tlearn: 0.5298958\ttotal: 1m 22s\tremaining: 27.9s\n",
            "748:\tlearn: 0.5296446\ttotal: 1m 23s\tremaining: 27.9s\n",
            "749:\tlearn: 0.5295260\ttotal: 1m 23s\tremaining: 27.8s\n",
            "750:\tlearn: 0.5295147\ttotal: 1m 23s\tremaining: 27.6s\n",
            "751:\tlearn: 0.5294297\ttotal: 1m 23s\tremaining: 27.5s\n",
            "752:\tlearn: 0.5291325\ttotal: 1m 23s\tremaining: 27.4s\n",
            "753:\tlearn: 0.5290675\ttotal: 1m 23s\tremaining: 27.3s\n",
            "754:\tlearn: 0.5288216\ttotal: 1m 23s\tremaining: 27.2s\n",
            "755:\tlearn: 0.5287430\ttotal: 1m 23s\tremaining: 27.1s\n",
            "756:\tlearn: 0.5285819\ttotal: 1m 23s\tremaining: 26.9s\n",
            "757:\tlearn: 0.5284266\ttotal: 1m 24s\tremaining: 26.8s\n",
            "758:\tlearn: 0.5283220\ttotal: 1m 24s\tremaining: 26.7s\n",
            "759:\tlearn: 0.5283141\ttotal: 1m 24s\tremaining: 26.6s\n",
            "760:\tlearn: 0.5282753\ttotal: 1m 24s\tremaining: 26.5s\n",
            "761:\tlearn: 0.5281947\ttotal: 1m 24s\tremaining: 26.3s\n",
            "762:\tlearn: 0.5280805\ttotal: 1m 24s\tremaining: 26.2s\n",
            "763:\tlearn: 0.5279175\ttotal: 1m 24s\tremaining: 26.1s\n",
            "764:\tlearn: 0.5278680\ttotal: 1m 24s\tremaining: 26s\n",
            "765:\tlearn: 0.5277260\ttotal: 1m 24s\tremaining: 25.9s\n",
            "766:\tlearn: 0.5275720\ttotal: 1m 24s\tremaining: 25.8s\n",
            "767:\tlearn: 0.5273623\ttotal: 1m 24s\tremaining: 25.6s\n",
            "768:\tlearn: 0.5269756\ttotal: 1m 24s\tremaining: 25.5s\n",
            "769:\tlearn: 0.5268071\ttotal: 1m 25s\tremaining: 25.4s\n",
            "770:\tlearn: 0.5265458\ttotal: 1m 25s\tremaining: 25.3s\n",
            "771:\tlearn: 0.5264664\ttotal: 1m 25s\tremaining: 25.2s\n",
            "772:\tlearn: 0.5264601\ttotal: 1m 25s\tremaining: 25.1s\n",
            "773:\tlearn: 0.5262961\ttotal: 1m 25s\tremaining: 24.9s\n",
            "774:\tlearn: 0.5262878\ttotal: 1m 25s\tremaining: 24.8s\n",
            "775:\tlearn: 0.5261936\ttotal: 1m 25s\tremaining: 24.7s\n",
            "776:\tlearn: 0.5261531\ttotal: 1m 25s\tremaining: 24.6s\n",
            "777:\tlearn: 0.5260513\ttotal: 1m 25s\tremaining: 24.5s\n",
            "778:\tlearn: 0.5258342\ttotal: 1m 25s\tremaining: 24.4s\n",
            "779:\tlearn: 0.5258185\ttotal: 1m 25s\tremaining: 24.2s\n",
            "780:\tlearn: 0.5256974\ttotal: 1m 26s\tremaining: 24.1s\n",
            "781:\tlearn: 0.5255776\ttotal: 1m 26s\tremaining: 24s\n",
            "782:\tlearn: 0.5254607\ttotal: 1m 26s\tremaining: 23.9s\n",
            "783:\tlearn: 0.5253661\ttotal: 1m 26s\tremaining: 23.8s\n",
            "784:\tlearn: 0.5252837\ttotal: 1m 26s\tremaining: 23.7s\n",
            "785:\tlearn: 0.5248357\ttotal: 1m 26s\tremaining: 23.5s\n",
            "786:\tlearn: 0.5248008\ttotal: 1m 26s\tremaining: 23.4s\n",
            "787:\tlearn: 0.5246394\ttotal: 1m 26s\tremaining: 23.3s\n",
            "788:\tlearn: 0.5244634\ttotal: 1m 26s\tremaining: 23.2s\n",
            "789:\tlearn: 0.5244343\ttotal: 1m 26s\tremaining: 23.1s\n",
            "790:\tlearn: 0.5244033\ttotal: 1m 26s\tremaining: 23s\n",
            "791:\tlearn: 0.5243344\ttotal: 1m 27s\tremaining: 22.8s\n",
            "792:\tlearn: 0.5243113\ttotal: 1m 27s\tremaining: 22.7s\n",
            "793:\tlearn: 0.5242181\ttotal: 1m 27s\tremaining: 22.6s\n",
            "794:\tlearn: 0.5240273\ttotal: 1m 27s\tremaining: 22.5s\n",
            "795:\tlearn: 0.5239289\ttotal: 1m 27s\tremaining: 22.4s\n",
            "796:\tlearn: 0.5237042\ttotal: 1m 27s\tremaining: 22.3s\n",
            "797:\tlearn: 0.5235561\ttotal: 1m 27s\tremaining: 22.2s\n",
            "798:\tlearn: 0.5234592\ttotal: 1m 27s\tremaining: 22s\n",
            "799:\tlearn: 0.5233807\ttotal: 1m 27s\tremaining: 21.9s\n",
            "800:\tlearn: 0.5232049\ttotal: 1m 28s\tremaining: 21.9s\n",
            "801:\tlearn: 0.5231007\ttotal: 1m 28s\tremaining: 21.8s\n",
            "802:\tlearn: 0.5229517\ttotal: 1m 28s\tremaining: 21.7s\n",
            "803:\tlearn: 0.5228620\ttotal: 1m 28s\tremaining: 21.6s\n",
            "804:\tlearn: 0.5228102\ttotal: 1m 28s\tremaining: 21.5s\n",
            "805:\tlearn: 0.5225718\ttotal: 1m 28s\tremaining: 21.3s\n",
            "806:\tlearn: 0.5223443\ttotal: 1m 28s\tremaining: 21.2s\n",
            "807:\tlearn: 0.5221277\ttotal: 1m 29s\tremaining: 21.2s\n",
            "808:\tlearn: 0.5220396\ttotal: 1m 29s\tremaining: 21.1s\n",
            "809:\tlearn: 0.5219409\ttotal: 1m 29s\tremaining: 21s\n",
            "810:\tlearn: 0.5219013\ttotal: 1m 29s\tremaining: 20.9s\n",
            "811:\tlearn: 0.5218482\ttotal: 1m 29s\tremaining: 20.7s\n",
            "812:\tlearn: 0.5218344\ttotal: 1m 29s\tremaining: 20.6s\n",
            "813:\tlearn: 0.5218210\ttotal: 1m 29s\tremaining: 20.5s\n",
            "814:\tlearn: 0.5217428\ttotal: 1m 29s\tremaining: 20.4s\n",
            "815:\tlearn: 0.5216210\ttotal: 1m 29s\tremaining: 20.3s\n",
            "816:\tlearn: 0.5215730\ttotal: 1m 30s\tremaining: 20.2s\n",
            "817:\tlearn: 0.5212351\ttotal: 1m 30s\tremaining: 20s\n",
            "818:\tlearn: 0.5212145\ttotal: 1m 30s\tremaining: 19.9s\n",
            "819:\tlearn: 0.5211779\ttotal: 1m 30s\tremaining: 19.8s\n",
            "820:\tlearn: 0.5211371\ttotal: 1m 30s\tremaining: 19.7s\n",
            "821:\tlearn: 0.5210842\ttotal: 1m 30s\tremaining: 19.6s\n",
            "822:\tlearn: 0.5209176\ttotal: 1m 30s\tremaining: 19.5s\n",
            "823:\tlearn: 0.5205916\ttotal: 1m 30s\tremaining: 19.4s\n",
            "824:\tlearn: 0.5204792\ttotal: 1m 30s\tremaining: 19.2s\n",
            "825:\tlearn: 0.5202132\ttotal: 1m 30s\tremaining: 19.1s\n",
            "826:\tlearn: 0.5202065\ttotal: 1m 30s\tremaining: 19s\n",
            "827:\tlearn: 0.5201807\ttotal: 1m 31s\tremaining: 18.9s\n",
            "828:\tlearn: 0.5201722\ttotal: 1m 31s\tremaining: 18.8s\n",
            "829:\tlearn: 0.5201421\ttotal: 1m 31s\tremaining: 18.7s\n",
            "830:\tlearn: 0.5199533\ttotal: 1m 31s\tremaining: 18.6s\n",
            "831:\tlearn: 0.5198769\ttotal: 1m 31s\tremaining: 18.5s\n",
            "832:\tlearn: 0.5197457\ttotal: 1m 31s\tremaining: 18.4s\n",
            "833:\tlearn: 0.5197255\ttotal: 1m 32s\tremaining: 18.3s\n",
            "834:\tlearn: 0.5196261\ttotal: 1m 32s\tremaining: 18.2s\n",
            "835:\tlearn: 0.5195225\ttotal: 1m 32s\tremaining: 18.1s\n",
            "836:\tlearn: 0.5193713\ttotal: 1m 32s\tremaining: 18s\n",
            "837:\tlearn: 0.5192241\ttotal: 1m 32s\tremaining: 17.9s\n",
            "838:\tlearn: 0.5190912\ttotal: 1m 32s\tremaining: 17.8s\n",
            "839:\tlearn: 0.5189141\ttotal: 1m 33s\tremaining: 17.7s\n",
            "840:\tlearn: 0.5188865\ttotal: 1m 33s\tremaining: 17.6s\n",
            "841:\tlearn: 0.5187904\ttotal: 1m 33s\tremaining: 17.5s\n",
            "842:\tlearn: 0.5186528\ttotal: 1m 33s\tremaining: 17.4s\n",
            "843:\tlearn: 0.5185420\ttotal: 1m 33s\tremaining: 17.3s\n",
            "844:\tlearn: 0.5182195\ttotal: 1m 33s\tremaining: 17.2s\n",
            "845:\tlearn: 0.5181684\ttotal: 1m 33s\tremaining: 17.1s\n",
            "846:\tlearn: 0.5181154\ttotal: 1m 34s\tremaining: 17s\n",
            "847:\tlearn: 0.5180256\ttotal: 1m 34s\tremaining: 16.9s\n",
            "848:\tlearn: 0.5179380\ttotal: 1m 34s\tremaining: 16.8s\n",
            "849:\tlearn: 0.5179073\ttotal: 1m 34s\tremaining: 16.6s\n",
            "850:\tlearn: 0.5177389\ttotal: 1m 34s\tremaining: 16.5s\n",
            "851:\tlearn: 0.5176354\ttotal: 1m 34s\tremaining: 16.4s\n",
            "852:\tlearn: 0.5176055\ttotal: 1m 34s\tremaining: 16.3s\n",
            "853:\tlearn: 0.5174545\ttotal: 1m 34s\tremaining: 16.2s\n",
            "854:\tlearn: 0.5173992\ttotal: 1m 34s\tremaining: 16.1s\n",
            "855:\tlearn: 0.5173039\ttotal: 1m 34s\tremaining: 15.9s\n",
            "856:\tlearn: 0.5172277\ttotal: 1m 34s\tremaining: 15.8s\n",
            "857:\tlearn: 0.5172207\ttotal: 1m 34s\tremaining: 15.7s\n",
            "858:\tlearn: 0.5168981\ttotal: 1m 35s\tremaining: 15.6s\n",
            "859:\tlearn: 0.5168212\ttotal: 1m 35s\tremaining: 15.5s\n",
            "860:\tlearn: 0.5166904\ttotal: 1m 35s\tremaining: 15.4s\n",
            "861:\tlearn: 0.5166168\ttotal: 1m 35s\tremaining: 15.3s\n",
            "862:\tlearn: 0.5166117\ttotal: 1m 35s\tremaining: 15.1s\n",
            "863:\tlearn: 0.5165992\ttotal: 1m 35s\tremaining: 15s\n",
            "864:\tlearn: 0.5165107\ttotal: 1m 35s\tremaining: 14.9s\n",
            "865:\tlearn: 0.5163056\ttotal: 1m 35s\tremaining: 14.8s\n",
            "866:\tlearn: 0.5162124\ttotal: 1m 35s\tremaining: 14.7s\n",
            "867:\tlearn: 0.5161682\ttotal: 1m 35s\tremaining: 14.6s\n",
            "868:\tlearn: 0.5161502\ttotal: 1m 35s\tremaining: 14.5s\n",
            "869:\tlearn: 0.5161281\ttotal: 1m 36s\tremaining: 14.4s\n",
            "870:\tlearn: 0.5160682\ttotal: 1m 36s\tremaining: 14.2s\n",
            "871:\tlearn: 0.5159876\ttotal: 1m 36s\tremaining: 14.1s\n",
            "872:\tlearn: 0.5159628\ttotal: 1m 36s\tremaining: 14s\n",
            "873:\tlearn: 0.5159306\ttotal: 1m 36s\tremaining: 13.9s\n",
            "874:\tlearn: 0.5158021\ttotal: 1m 36s\tremaining: 13.8s\n",
            "875:\tlearn: 0.5157965\ttotal: 1m 36s\tremaining: 13.7s\n",
            "876:\tlearn: 0.5155503\ttotal: 1m 36s\tremaining: 13.6s\n",
            "877:\tlearn: 0.5153880\ttotal: 1m 36s\tremaining: 13.4s\n",
            "878:\tlearn: 0.5153629\ttotal: 1m 36s\tremaining: 13.3s\n",
            "879:\tlearn: 0.5153129\ttotal: 1m 36s\tremaining: 13.2s\n",
            "880:\tlearn: 0.5152528\ttotal: 1m 37s\tremaining: 13.1s\n",
            "881:\tlearn: 0.5152267\ttotal: 1m 37s\tremaining: 13s\n",
            "882:\tlearn: 0.5151542\ttotal: 1m 37s\tremaining: 12.9s\n",
            "883:\tlearn: 0.5150819\ttotal: 1m 37s\tremaining: 12.8s\n",
            "884:\tlearn: 0.5149142\ttotal: 1m 37s\tremaining: 12.7s\n",
            "885:\tlearn: 0.5147917\ttotal: 1m 37s\tremaining: 12.5s\n",
            "886:\tlearn: 0.5147857\ttotal: 1m 37s\tremaining: 12.4s\n",
            "887:\tlearn: 0.5146711\ttotal: 1m 37s\tremaining: 12.3s\n",
            "888:\tlearn: 0.5144706\ttotal: 1m 37s\tremaining: 12.2s\n",
            "889:\tlearn: 0.5143482\ttotal: 1m 37s\tremaining: 12.1s\n",
            "890:\tlearn: 0.5142514\ttotal: 1m 37s\tremaining: 12s\n",
            "891:\tlearn: 0.5141239\ttotal: 1m 38s\tremaining: 11.9s\n",
            "892:\tlearn: 0.5140832\ttotal: 1m 38s\tremaining: 11.8s\n",
            "893:\tlearn: 0.5140534\ttotal: 1m 38s\tremaining: 11.6s\n",
            "894:\tlearn: 0.5139433\ttotal: 1m 38s\tremaining: 11.5s\n",
            "895:\tlearn: 0.5139291\ttotal: 1m 38s\tremaining: 11.4s\n",
            "896:\tlearn: 0.5138393\ttotal: 1m 38s\tremaining: 11.3s\n",
            "897:\tlearn: 0.5137506\ttotal: 1m 38s\tremaining: 11.2s\n",
            "898:\tlearn: 0.5134687\ttotal: 1m 38s\tremaining: 11.1s\n",
            "899:\tlearn: 0.5132359\ttotal: 1m 38s\tremaining: 11s\n",
            "900:\tlearn: 0.5130263\ttotal: 1m 38s\tremaining: 10.9s\n",
            "901:\tlearn: 0.5128984\ttotal: 1m 38s\tremaining: 10.7s\n",
            "902:\tlearn: 0.5128870\ttotal: 1m 39s\tremaining: 10.6s\n",
            "903:\tlearn: 0.5128343\ttotal: 1m 39s\tremaining: 10.5s\n",
            "904:\tlearn: 0.5126661\ttotal: 1m 39s\tremaining: 10.4s\n",
            "905:\tlearn: 0.5124504\ttotal: 1m 39s\tremaining: 10.3s\n",
            "906:\tlearn: 0.5122621\ttotal: 1m 39s\tremaining: 10.2s\n",
            "907:\tlearn: 0.5121956\ttotal: 1m 39s\tremaining: 10.1s\n",
            "908:\tlearn: 0.5121623\ttotal: 1m 39s\tremaining: 9.96s\n",
            "909:\tlearn: 0.5119833\ttotal: 1m 39s\tremaining: 9.86s\n",
            "910:\tlearn: 0.5119608\ttotal: 1m 39s\tremaining: 9.74s\n",
            "911:\tlearn: 0.5118271\ttotal: 1m 39s\tremaining: 9.63s\n",
            "912:\tlearn: 0.5117810\ttotal: 1m 39s\tremaining: 9.52s\n",
            "913:\tlearn: 0.5116189\ttotal: 1m 40s\tremaining: 9.41s\n",
            "914:\tlearn: 0.5113615\ttotal: 1m 40s\tremaining: 9.3s\n",
            "915:\tlearn: 0.5113234\ttotal: 1m 40s\tremaining: 9.19s\n",
            "916:\tlearn: 0.5111908\ttotal: 1m 40s\tremaining: 9.08s\n",
            "917:\tlearn: 0.5111376\ttotal: 1m 40s\tremaining: 8.97s\n",
            "918:\tlearn: 0.5110724\ttotal: 1m 40s\tremaining: 8.86s\n",
            "919:\tlearn: 0.5109072\ttotal: 1m 40s\tremaining: 8.74s\n",
            "920:\tlearn: 0.5107836\ttotal: 1m 40s\tremaining: 8.63s\n",
            "921:\tlearn: 0.5107608\ttotal: 1m 40s\tremaining: 8.52s\n",
            "922:\tlearn: 0.5106851\ttotal: 1m 40s\tremaining: 8.41s\n",
            "923:\tlearn: 0.5106269\ttotal: 1m 40s\tremaining: 8.3s\n",
            "924:\tlearn: 0.5104733\ttotal: 1m 40s\tremaining: 8.19s\n",
            "925:\tlearn: 0.5103439\ttotal: 1m 41s\tremaining: 8.08s\n",
            "926:\tlearn: 0.5103175\ttotal: 1m 41s\tremaining: 7.97s\n",
            "927:\tlearn: 0.5102266\ttotal: 1m 41s\tremaining: 7.86s\n",
            "928:\tlearn: 0.5101648\ttotal: 1m 41s\tremaining: 7.75s\n",
            "929:\tlearn: 0.5100679\ttotal: 1m 41s\tremaining: 7.63s\n",
            "930:\tlearn: 0.5099640\ttotal: 1m 41s\tremaining: 7.52s\n",
            "931:\tlearn: 0.5099042\ttotal: 1m 41s\tremaining: 7.41s\n",
            "932:\tlearn: 0.5096813\ttotal: 1m 41s\tremaining: 7.3s\n",
            "933:\tlearn: 0.5096381\ttotal: 1m 41s\tremaining: 7.19s\n",
            "934:\tlearn: 0.5096091\ttotal: 1m 41s\tremaining: 7.08s\n",
            "935:\tlearn: 0.5094601\ttotal: 1m 41s\tremaining: 6.97s\n",
            "936:\tlearn: 0.5093398\ttotal: 1m 42s\tremaining: 6.86s\n",
            "937:\tlearn: 0.5091084\ttotal: 1m 42s\tremaining: 6.75s\n",
            "938:\tlearn: 0.5087548\ttotal: 1m 42s\tremaining: 6.64s\n",
            "939:\tlearn: 0.5085964\ttotal: 1m 42s\tremaining: 6.53s\n",
            "940:\tlearn: 0.5084635\ttotal: 1m 42s\tremaining: 6.42s\n",
            "941:\tlearn: 0.5084180\ttotal: 1m 42s\tremaining: 6.31s\n",
            "942:\tlearn: 0.5082880\ttotal: 1m 42s\tremaining: 6.2s\n",
            "943:\tlearn: 0.5081773\ttotal: 1m 42s\tremaining: 6.09s\n",
            "944:\tlearn: 0.5080520\ttotal: 1m 42s\tremaining: 5.98s\n",
            "945:\tlearn: 0.5078086\ttotal: 1m 42s\tremaining: 5.87s\n",
            "946:\tlearn: 0.5076272\ttotal: 1m 43s\tremaining: 5.76s\n",
            "947:\tlearn: 0.5075755\ttotal: 1m 43s\tremaining: 5.65s\n",
            "948:\tlearn: 0.5073000\ttotal: 1m 43s\tremaining: 5.55s\n",
            "949:\tlearn: 0.5072716\ttotal: 1m 43s\tremaining: 5.44s\n",
            "950:\tlearn: 0.5072135\ttotal: 1m 43s\tremaining: 5.33s\n",
            "951:\tlearn: 0.5068947\ttotal: 1m 43s\tremaining: 5.22s\n",
            "952:\tlearn: 0.5067211\ttotal: 1m 43s\tremaining: 5.11s\n",
            "953:\tlearn: 0.5066744\ttotal: 1m 43s\tremaining: 5s\n",
            "954:\tlearn: 0.5066185\ttotal: 1m 43s\tremaining: 4.89s\n",
            "955:\tlearn: 0.5065405\ttotal: 1m 43s\tremaining: 4.78s\n",
            "956:\tlearn: 0.5064525\ttotal: 1m 44s\tremaining: 4.67s\n",
            "957:\tlearn: 0.5062840\ttotal: 1m 44s\tremaining: 4.57s\n",
            "958:\tlearn: 0.5061750\ttotal: 1m 44s\tremaining: 4.46s\n",
            "959:\tlearn: 0.5061375\ttotal: 1m 44s\tremaining: 4.36s\n",
            "960:\tlearn: 0.5061269\ttotal: 1m 44s\tremaining: 4.25s\n",
            "961:\tlearn: 0.5060650\ttotal: 1m 44s\tremaining: 4.14s\n",
            "962:\tlearn: 0.5059903\ttotal: 1m 45s\tremaining: 4.04s\n",
            "963:\tlearn: 0.5059287\ttotal: 1m 45s\tremaining: 3.93s\n",
            "964:\tlearn: 0.5058614\ttotal: 1m 45s\tremaining: 3.82s\n",
            "965:\tlearn: 0.5057372\ttotal: 1m 45s\tremaining: 3.71s\n",
            "966:\tlearn: 0.5055594\ttotal: 1m 45s\tremaining: 3.61s\n",
            "967:\tlearn: 0.5054803\ttotal: 1m 45s\tremaining: 3.5s\n",
            "968:\tlearn: 0.5054237\ttotal: 1m 46s\tremaining: 3.39s\n",
            "969:\tlearn: 0.5052991\ttotal: 1m 46s\tremaining: 3.28s\n",
            "970:\tlearn: 0.5051899\ttotal: 1m 46s\tremaining: 3.18s\n",
            "971:\tlearn: 0.5051839\ttotal: 1m 46s\tremaining: 3.07s\n",
            "972:\tlearn: 0.5050888\ttotal: 1m 46s\tremaining: 2.96s\n",
            "973:\tlearn: 0.5048937\ttotal: 1m 46s\tremaining: 2.85s\n",
            "974:\tlearn: 0.5047753\ttotal: 1m 46s\tremaining: 2.74s\n",
            "975:\tlearn: 0.5046400\ttotal: 1m 46s\tremaining: 2.63s\n",
            "976:\tlearn: 0.5044676\ttotal: 1m 47s\tremaining: 2.52s\n",
            "977:\tlearn: 0.5044383\ttotal: 1m 47s\tremaining: 2.41s\n",
            "978:\tlearn: 0.5043000\ttotal: 1m 47s\tremaining: 2.3s\n",
            "979:\tlearn: 0.5042003\ttotal: 1m 47s\tremaining: 2.19s\n",
            "980:\tlearn: 0.5041773\ttotal: 1m 47s\tremaining: 2.08s\n",
            "981:\tlearn: 0.5041307\ttotal: 1m 47s\tremaining: 1.97s\n",
            "982:\tlearn: 0.5040316\ttotal: 1m 47s\tremaining: 1.86s\n",
            "983:\tlearn: 0.5039809\ttotal: 1m 47s\tremaining: 1.75s\n",
            "984:\tlearn: 0.5039415\ttotal: 1m 47s\tremaining: 1.64s\n",
            "985:\tlearn: 0.5038725\ttotal: 1m 47s\tremaining: 1.53s\n",
            "986:\tlearn: 0.5037108\ttotal: 1m 47s\tremaining: 1.42s\n",
            "987:\tlearn: 0.5036604\ttotal: 1m 48s\tremaining: 1.31s\n",
            "988:\tlearn: 0.5035944\ttotal: 1m 48s\tremaining: 1.2s\n",
            "989:\tlearn: 0.5035719\ttotal: 1m 48s\tremaining: 1.09s\n",
            "990:\tlearn: 0.5035103\ttotal: 1m 48s\tremaining: 983ms\n",
            "991:\tlearn: 0.5034699\ttotal: 1m 48s\tremaining: 874ms\n",
            "992:\tlearn: 0.5034634\ttotal: 1m 48s\tremaining: 764ms\n",
            "993:\tlearn: 0.5033850\ttotal: 1m 48s\tremaining: 655ms\n",
            "994:\tlearn: 0.5032400\ttotal: 1m 48s\tremaining: 546ms\n",
            "995:\tlearn: 0.5031962\ttotal: 1m 48s\tremaining: 437ms\n",
            "996:\tlearn: 0.5030084\ttotal: 1m 48s\tremaining: 327ms\n",
            "997:\tlearn: 0.5027720\ttotal: 1m 48s\tremaining: 218ms\n",
            "998:\tlearn: 0.5026862\ttotal: 1m 48s\tremaining: 109ms\n",
            "999:\tlearn: 0.5025418\ttotal: 1m 49s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x796a7025cf80>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# <USE IT!>\n",
        "clf = CatBoostClassifier()\n",
        "clf.fit(sparse_data_train, clean_data_train['average_bill'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBOpZY9BGH7Q"
      },
      "source": [
        "**11. Пришлите в Контест balanced_accuracy_score на тестовой выборке, округлённый до двух знаков после запятой**. Стало ли сильно лучше от того, что мы воспользовались таким крутым классификатором?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bas_forTest = balanced_accuracy_score(clean_data_test['average_bill'], np.round(clf.predict(sparse_data_test_df)/500)*500)\n",
        "print(bas_forTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZqgaOS0xOMg",
        "outputId": "729e6ee9-6094-4d0d-f62d-b8550efb8126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3617309411101425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7534c40c"
      },
      "source": [
        "bas_forTest = balanced_accuracy_score(sparse_data_train, clf.predict(sparse_data_test))\n",
        "print(bas_forTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsoEltkmz4hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0d59027"
      },
      "source": [
        "Here are some key takeaways from this notebook:\n",
        "\n",
        "*   **Data Loading and Exploration**: We loaded and explored the `organisations.csv`, `features.csv`, and `rubrics.csv` datasets using pandas. Key columns for our task are `city`, `average_bill`, `rating`, `rubrics_id`, and `features_id`.\n",
        "*   **Data Cleaning**: We handled missing values in the `average_bill` column by dropping rows and removed outliers where `average_bill` was greater than 2500.\n",
        "*   **Problem Formulation**: We discussed whether the task of predicting `average_bill` is a classification or regression problem, concluding it can be approached as either.\n",
        "*   **Evaluation Metrics**: We considered appropriate metrics for both classification (balanced accuracy) and regression (RMSE, MAE), highlighting the importance of choosing metrics that align with the problem's goals.\n",
        "*   **Data Splitting**: We split the data into training and testing sets using `train_test_split` with `random_state=42` and `stratify` to ensure consistent distribution of the target variable.\n",
        "*   **Baselines**: We implemented simple baseline models: a `MeanRegressor` (predicts the mean average bill) and a `MostFrequentClassifier` (predicts the most frequent average bill).\n",
        "*   **Feature Engineering**:\n",
        "    *   We incorporated the `city` feature to build a `CityMeanRegressor` that predicts the average bill based on the city.\n",
        "    *   We created a `modified_rubrics` feature by grouping less frequent rubric combinations into an 'other' category.\n",
        "    *   We combined `rubrics_id` and `features_id` into a single `modified_features` column and handled unseen combinations in the test set by labeling them as 'other'.\n",
        "    *   We transformed categorical and bag-of-features data into a sparse matrix format suitable for models like CatBoost.\n",
        "*   **Model Training and Evaluation**: We trained and evaluated different models, including the baseline models, the city-based regressor, a rubric/city median classifier, and a CatBoost classifier, comparing their performance using the chosen metrics.\n",
        "*   **Overfitting**: We observed overfitting when using a complex model (`AllFeaturesMedianClassifier` based on `modified_features`) on limited data, where the model performed very well on the training data but poorly on the test data. This highlights the importance of balancing model complexity and data availability.\n",
        "*   **CatBoost**: We used CatBoost, a powerful gradient boosting library, demonstrating how to prepare data (sparse matrix) for such models.\n",
        "\n",
        "These points cover the main steps and concepts explored in the notebook, from data preparation to model evaluation and understanding the challenges of model complexity and data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}